name: Football Match Outcome Prediction
description: |
  Sports betting corporations try to give accurate predictions of the outcome of upcoming matches. It's important to understand the data and the prediction model to get accurate predictions.
  
  This is an implementation of a data science pipeline that predicts the outcome of a football match.
id: c9f9eab1-a025-43c5-a511-d45cb318a79e
UMLDiagramUrl: https://lucid.app/documents/embeddedchart/4341ec97-ee9d-4f0a-a75f-b990a65e8747
prerequisites:
  - 5f912335-2c00-4c94-bb8f-4610191ca1e8
  - 2c1a3fe9-9cd1-48af-90f0-e900dc2d78ee
requires_aws: False
milestones:
  - name: EDA and Data Cleaning
    tasks:
      - name: Download the data
        id: 6916a0a4-37df-47fb-990a-5cc3f7c076d7
        description: |
          Get the data from the following [link](https://aicore-files.s3.amazonaws.com/Data-Science/Football-Dataset.zip)
        duration: 1
      - name: Find the relationships amongst variables
        id: 243dac9d-d91b-4cac-94e4-36a626fcfd3d
        description: |
          You just need to find high level relationships amongst the variables. Don't worry about giving weight to these relationships.

          For example, for each league, can you find how many teams you have? This might be useful when you are analyzing the data for each country.
        prerequisites:
          - 3cf7e51f-6122-4e8a-b8d7-25bf65f1329c # Data Cleaning
          - 43bd7ba0-8032-4020-bc94-d0e6b00034b0 # Data Formats and Pandas
        duration: 2
      - name: Find trends in the features of the dataset
        id: d41dfb02-0eeb-447c-b8f8-78b6e2c642d0
        description: |
          You just need to find trends in the features of the dataset. Once again, don't worry about giving weight to these trends.

          For example, for each year, does the trend of the number of home wins change?
        prerequisites: 
          - 3cf7e51f-6122-4e8a-b8d7-25bf65f1329c # Data Cleaning
          - 43bd7ba0-8032-4020-bc94-d0e6b00034b0 # Data Formats and Pandas
        duration: 2
      - name: Complete your dataset
        id: aac4d438-32ed-4e7f-ae6f-3addb45c1bad
        description: |
          Download the next files that contain data about each match and the stadium of each team:

          [Match Data](https://aicore-files.s3.amazonaws.com/Data-Science/Match_Info.csv)

          [Team Data](https://aicore-files.s3.amazonaws.com/Data-Science/Team_Info.csv)
        duration: 3
      
      - name: Create a report with some hypotheses about the predictive power of the features
        id: 58e762de-551a-4370-8c76-2057e04f7d4c
        description: |
          With the data you have, can you guess what features will be more important for predicting the outcome of the match?
        duration: 2
      - name: Begin documenting your experience
        id: 96b7b089-3327-40a8-b4d1-1742c24e23dc
        description: |
          Now that you have performed EDA and determined the trends in the dataset, add documentation to your README file following this [guide](https://github.com/AI-Core/ExampleDocumentation).

          Include brief descriptions on EDA and data cleaning and include some of what you have written in your report.
        duration: 0
    description: ''
    duration: 10
    id: 79a9d62e-78fa-496a-beb9-ca62945cebf0

  - name: Feature Engineering
    tasks:
      - name: Extract the ELO of each team included in the link of each match. 
        id: f843e789-fde8-4ccc-aca9-7b4537010075
        description: | 
          To save you time, we have already extracted the ELO of each match. You can download a pickle file from this [link](https://aicore-files.s3.amazonaws.com/Data-Science/elo_dict.pkl)

          The pickle contains a dictionary where each key is the URL of the match, and the value is another dictionary with the ELOs of each team. You can unpickle the file using the following code:

          `import pickle`
          
          `pickle.load(open('elo_dict.pkl', 'rb'))`
        prerequisites:
          - 38fe6a4d-f937-4ef2-8bd9-305da0223cd4 # Data Collection
        duration: 2
      # - name: Scrape for new features
      #   id: 7bb04190-f01b-4fc1-b3b5-e9258ba95d35
      #   prerequisites: 
      #     - 43bd7ba0-8032-4020-bc94-d0e6b00034b0 # Data Formats and Pandas
      #     - 38fe6a4d-f937-4ef2-8bd9-305da0223cd4 # Data Collection
      #   duration: 2
      - name: Create new features (Total Goals so far, Total Goals so far, Streak...)
        id: afb880f6-5c91-489c-bee7-a948aa8f2922
        prerequisites: 
          - 43bd7ba0-8032-4020-bc94-d0e6b00034b0 # Data Formats and Pandas
          - dae521a4-80ac-40a3-bbc2-d6a7779f9de0 # intro to ML
        duration: 3
      - name: Create a new dataset with the new features
        id: def507ac-11c1-4dca-93c1-c2c729117472
        description: |
          From the first step in this project, you have done a lot of things. It's a good idea to have a pipeline to repeat all the steps you have done so far.

          That way, next time you need to add new data, you can just add it to the pipeline and it will be done for you.
          
          Make sure that the dataset contains only numerical values, since it will be used in the machine learning algorithms, and save the file as `cleaned_dataset.csv`
        prerequisites: 
          - 43bd7ba0-8032-4020-bc94-d0e6b00034b0 # Data Formats and Pandas
          - dae521a4-80ac-40a3-bbc2-d6a7779f9de0 # intro to ML
        duration: 2
      - name: Update your documentation
        id: 1978dc40-e0d6-4c7a-ac6d-907a1ba30f54
        description: |
          Update your README with what you have done for this milestone, making sure to follow the guide provided.

          Include a brief description of what feature engineering is and what you did to your features and why.

          Also include how you setup your pipeline.
        duration: 0
    description: ''
    duration: 7
    id: 825a4e31-bf78-4deb-9367-ba5b6eccac75

  - name: Upload the data to the database
    id: 7c19acaf-32d9-4c02-aa2a-ff44a930d23f
    tasks:
      - name: Create a script to create and upload the dataset to the database
        id: 7aa179ba-982c-4636-9c0d-da8ae411830c
        description: |
          You should spin up an AWS RDS instance. For this project, you can get away with selecting a low-cost server to run it. Under DB Instance Class, select 'burstable class' and select the t3.micro from the dropdown.
        prerequisites: 
          - 51911a90-cb6b-4455-810a-940ffcb63bd3
        duration: 2
      - name: Create a pipeline to systematize all the steps done so far
        id: 4a48da42-19c9-4435-8673-6cb515cb1fcc
        description: |
          The new data that you will obtain needs to undergo all the steps you have taken so far. The script should scrape new data, clean it, and upsert it into the database.

          The pipeline should be saved as a Python script and saved under the name `pipeline.py`.
        prerequisites: 
          - 51911a90-cb6b-4455-810a-940ffcb63bd3
        duration: 3
      - name: Update your documentation
        id: 93461848-3446-4245-afda-e52b6964706c
        description: |
          Update your README file, talk about how you setup an RDS instance and cloud services that you are using.

          Include how you populate your RDS instance (SQL commands, sqlalchemy/psycopg2).
        duration: 0
    description: ''
    duration: 5

  - name: Model Training
    tasks:
      - name: Train a simple model to obtain a baseline score
        id: 276bf7e9-9307-42bf-b1ce-befecf59f722
        prerequisites: 
          - dae521a4-80ac-40a3-bbc2-d6a7779f9de0 # intro to ML
        duration: 1
      - name: Perform a feature selection, for example, using LASSO regression
        id: 1d6fc1a0-3b64-49ba-b429-3a76bd1122b2
        prerequisites: 
          - f7ffc03c-84f1-4ee2-a6e0-6feb040021df # Popular Supervised Models
        duration: 3
      - name: Train and tune other models (e.g. Random Forest, XGBoost) to obtain better scores
        id: bb5b0534-dc35-45db-ba21-37c1587cf3ba
        prerequisites:
          - 2c1a3fe9-9cd1-48af-90f0-e900dc2d78ee # Ensemble
        duration: 3
      - name: Based on the models you trained, iteratively train the model with different subsets of the data
        id: 63c10fe3-967c-4e3c-bf35-9a355bc02f39
        description: |
          On many Data Science project, you will use Notebooks to, apart getting the clean data and training the model, explain the model and explain the results as if you were explaining it to a customer.

          This is a good time to do it, create a notebook that explains the model you trained and the results you obtained and call it `model_explained.ipynb`.
        prerequisites: 
          - 2c1a3fe9-9cd1-48af-90f0-e900dc2d78ee # Ensemble
        duration: 4
      - name: Update your documentation
        id: 0cb1fb21-14d7-449f-b4b2-a86f661c6851
        description: |
          Now that you have trained your model, update your README file with your process for model training.

          Include brief descriptions of the models you used as well as the methods you used for feature selection and give reasons as to why you chose that model.
        duration: 1
    description: ''
    duration: 12
    id: a278e285-1dc8-4757-a5d6-94dc36aa7deb

  - name: Inference
    tasks:
      - name: Scrape data of matches that haven't taken place for making predictions
        id: 39963186-a4a0-4223-a134-8a399875e517
        prerequisites:
          - 38fe6a4d-f937-4ef2-8bd9-305da0223cd4 # Data Collection
        duration: 2
      - name: Use the pipeline you created to clean the scraped data
        id: 0956c671-8abf-42cb-b8f9-ce8c61baaacf
        description: |
          The data you scraped needs to be cleaned. The pipeline you created should be used to clean the data.

          The cleaned data should be saved as `cleaned_results.csv`
        prerequisites: 
          - 43bd7ba0-8032-4020-bc94-d0e6b00034b0 # Data Formats and Pandas
          - dae521a4-80ac-40a3-bbc2-d6a7779f9de0 # intro to ML
        duration: 2
      - name: Use the model to predict the results of the next matches
        id: 94f5a0e6-90eb-477f-a138-ba167666a1d9
        description: |
          As with the model training, inference can be done in a notebook.

          Create the notebook to give explanations of the model and the results of the predictions, and name the notebook `model_results.ipynb`.
        prerequisites: 
          - dae521a4-80ac-40a3-bbc2-d6a7779f9de0 # intro to ML
        duration: 1
      - name: Update your documentation
        id: a1081f0d-0951-427e-a6e1-58ab2948f251
        description: |
          Congratulations on finishing your project! Update your README file with what you have done for this milestone.

          Don't forget to include the conclusions you have drawn from the models performance and how you would improve the model/data.

          Go back over your entire documentation to make sure everything is clear, concise and reads well.
        duration: 0
    description: ''
    duration: 5
    id: 3799b985-70f3-4891-8873-998d5fd7ad1b

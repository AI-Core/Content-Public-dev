name: Football Match Outcome Prediction
description: |
  Sports betting corporations try to give accurate predictions of the outcome of upcoming matches. It's important to understand the data and the prediction model to get accurate predictions.

  This is an implementation of a data science pipeline that predicts the outcome of a football match.
id: c9f9eab1-a025-43c5-a511-d45cb318a79e
UMLDiagramUrl: https://lucid.app/documents/embeddedchart/4341ec97-ee9d-4f0a-a75f-b990a65e8747
requires_github: True
requires_aws: False
rotate_to: ec1090b6-791b-4a2a-8aa6-6575c48f29bb
milestones:
  - name: Set up the environment
    tasks:
      - name: Join the project calendar
        id: b5dea7b5-eff5-43bd-bba7-49566a2f7e3f
        description: |
          To keep up with all the events associated with this project, please join its respective Google Calendar using this [link](https://calendar.google.com/calendar/u/1?cid=Y19kcTRsbzc5YjA5NmtmMW0xMm1lYmljY2I0b0Bncm91cC5jYWxlbmRhci5nb29nbGUuY29t).
        duration: 0
      - name: Set up GitHub
        id: 032dcdb6-69e1-450c-96aa-819a45d6caa1
        description: |
          In this project, you'll use GitHub to track changes to your code and save them online in a GitHub repo. Hit the button on the right to automatically create a new GitHub repo. We'll tell you when you need to use it as you go through the project.
        duration: 1
        prerequisites:
          - 86076c6d-6df5-4c14-8f5e-7d3dfe661de6
          - b457ee87-74b7-414d-bbc8-43fb8acc8cc4
    description: Set up your dev environment to get started
    id: 793ccbbd-0d50-40df-9fc8-42c49438da61

  - name: EDA and Data Cleaning
    description: |
      In this milestone, you'll explore the data and clean it to prepare it for modelling. You will get familiar with pandas and its methods.
    tasks:
      - name: Download the data
        id: 6916a0a4-37df-47fb-990a-5cc3f7c076d7
        description: |
          Get the data from the following [link](https://aicore-files.s3.amazonaws.com/Data-Science/Football.zip)
        duration: 2
      - name: Find the relationships amongst variables
        id: 243dac9d-d91b-4cac-94e4-36a626fcfd3d
        description: |
          You just need to find high level relationships amongst the variables. Don't worry about giving weight to these relationships.

          For example, for each league, can you find how many teams you have? This might be useful when you are analyzing the data for each country.

          This and other tasks you will find in this milestone don't have a fixed solution, you need to interpret the data you have and get some insights; but everyone will have a different way of looking at the data.
        prerequisites:
          - 3fad431d-917f-4989-abc8-6d22d2961e37 # 1 Data Cleaning in Pandas
          - 2f2a6aee-4b86-4aea-bdee-962b61c3ddb4 # 2 EDA and Basic Visualisation
          - b17e0a6b-68db-4a1f-9433-04ab57d6da3a # 3 Missing Data
          - 45d60050-aef5-400b-a6cb-e35f35f9ace9 # 2 Data and File Formats
          - 7e5a5266-ea05-4aa6-9bbe-b8affd65e280 # 3 Intro to Pandas
        duration: 8
      - name: Compute the winner of the match
        id: d41dfb02-0eeb-447c-b8f8-78b6e2c642d0
        description: |
          As a data scientist, you need to understand the data and the prediction model to get accurate predictions.

          Your model won't tell you the name of the winner.
          Instead, it will predict the probability of each team to win.

          Compute the winner of each match using the result. 
          While this sounds trivial, your computer won't know how to interpret "1-3" for example, and know that it represents a loss from the perspective of the home team.
        duration: 2
      - name: Complete your dataset
        id: aac4d438-32ed-4e7f-ae6f-3addb45c1bad
        description: |
          Download the next files that contain data about each match and the stadium of each team:
          [Match Data](https://aicore-files.s3.amazonaws.com/Data-Science/Match_Info.csv)
          [Team Data](https://aicore-files.s3.amazonaws.com/Data-Science/Team_Info.csv)
        duration: 4

      # - name: Create a report with some hypotheses about the predictive power of the features
      #   id: 58e762de-551a-4370-8c76-2057e04f7d4c
      #   description: |
      #     With the data you have, can you guess what features will be more important for predicting the outcome of the match?
      #   prerequisites:
      #     - 89b7fb50-9de8-46a4-bf86-d54cf316b899 # 1 Data for ML
      #   duration: 4
      - name: Begin documenting your experience
        id: 96b7b089-3327-40a8-b4d1-1742c24e23dc
        description: |
          Now that you have performed EDA and determined the trends in the dataset, add documentation to your README file following this [guide](https://github.com/AI-Core/ExampleDocumentation).
          Include brief descriptions on EDA and data cleaning and include some of what you have written in your report.
        duration: 2
    id: 79a9d62e-78fa-496a-beb9-ca62945cebf0

  - name: Feature Engineering
    description: |
      In this milestone, you'll engineer new features from the existing ones, in other words, you'll create new variables that will help you predict the outcome of the match.
    tasks:
      - name: Extract the ELO of each team included in the link of each match.
        id: f843e789-fde8-4ccc-aca9-7b4537010075
        description: |
          To save you time, we have already extracted the ELO of each match. You can download a pickle file from this [link](https://aicore-files.s3.amazonaws.com/Data-Science/elo_dict.pkl)

          The pickle contains a dictionary where each key is the URL of the match, and the value is another dictionary with the ELOs of each team. You can unpickle the file using the following code:
          `import pickle`

          `pickle.load(open('elo_dict.pkl', 'rb'))`
        prerequisites:
          - bf5e1b7b-0556-4417-809a-85e544ba2e0e # 1 APIs and requests
          - ee468b4e-b54c-464f-becb-caa81721ad06 # 2 Web Scraping
        duration: 4

      - name: Create new features (Total goals so far, Total points so far, Streak...)
        description: |
          This task is rather complicated, and there are many ways to tackle input.
          One possibility to get, for example, the total goals so far, is to iterate through the matches of each round, and see the goals for each team. With that information, create an auxiliary table that contains the total goals so far for each team. Then, iterate through the matches of the next round, fill in the column of "Total Goals so far" in the main table with the data you obtained in the auxiliary table. Then, check the goals again for each team, find the team in the auxiliary table and add the goals to the total goals so far. Repeat this process for all the rounds in the season, and repeat the process for all the seasons in the league.
          As you can see, the procedure requires quite a few loops, some of them might have nested loops. Don't worry about it, we don't need to optimize the running time.
          This is just an example on how to get the total goals so far. Think about other features such as total points or streak
        id: afb880f6-5c91-489c-bee7-a948aa8f2922
        duration: 10
      - name: Create a new dataset with the new features
        id: def507ac-11c1-4dca-93c1-c2c729117472
        description: |
          From the first step in this project, you have done a lot of things. It's a good idea to have a pipeline to repeat all the steps you have done so far.
          That way, next time you need to add new data, you can just add it to the pipeline and it will be done for you.

          Make sure that the dataset contains only numerical values, since it will be used in the machine learning algorithms, and save the file as `cleaned_dataset.csv`
        duration: 4
      - name: Update your documentation
        id: 1978dc40-e0d6-4c7a-ac6d-907a1ba30f54
        description: |
          Update your README with what you have done for this milestone, making sure to follow the guide provided.
          Include a brief description of what feature engineering is and what you did to your features and why.
          Also include how you setup your pipeline.
        duration: 1
    id: 825a4e31-bf78-4deb-9367-ba5b6eccac75

  # - name: Upload the data to the database
  #   description: |
  #     Once the data is cleaned and ready to be used, you need to upload it to the database, so that you don't have to preprocess again next time you need to use it.
  #   id: 7c19acaf-32d9-4c02-aa2a-ff44a930d23f
  #   tasks:
  #     - name: Create a script to create and upload the dataset to the database
  #       id: 7aa179ba-982c-4636-9c0d-da8ae411830c
  #       description: |
  #         You should spin up an AWS RDS instance. For this project, you can get away with selecting a low-cost server to run it. Under DB Instance Class, select 'burstable class' and select the t3.micro from the dropdown.
  #       prerequisites:
  #         - ec099114-05ce-4299-96da-8b372b4f432d
  #       duration: 4
  #     - name: Create a pipeline to systematize all the steps done so far
  #       id: 4a48da42-19c9-4435-8673-6cb515cb1fcc
  #       description: |
  #         The new data that you will obtain needs to undergo all the steps you have taken so far. The script should scrape new data, clean it, and upsert it into the database.
  #         The pipeline should be saved as a Python script and saved under the name `pipeline.py`.
  #       prerequisites:
  #         - 84a9c4c6-3bb2-4095-a96a-6d4ec15498c3 # 7 pyscopg2 and SQLAlchemy
  #       duration: 3
  #     - name: Update your documentation
  #       id: 93461848-3446-4245-afda-e52b6964706c
  #       description: |
  #         Update your README file, talk about how you setup an RDS instance and cloud services that you are using.
  #         Include how you populate your RDS instance (SQL commands, sqlalchemy/psycopg2).
  #       duration: 1

  - name: Model Training
    description: |
      In this milestone, you'll train a model to predict the outcome of a match. You will start with a simple model and then improve it.
    tasks:
      - name: Train a simple model to obtain a baseline score
        id: 276bf7e9-9307-42bf-b1ce-befecf59f722
        description: |
          The usual workflow when you are looking for a good model is:
          1. Train a simple model to obtain a baseline score
          2. Perform feature selection
          3. Train multiple models with the selected features and tune their hyperparameters
          4. Pick the best model
          5. Test the model on the testing set
          6. See if there is room for improvement on the dataset (e.g. by removing features, or picking a subset that represents better the current behaviour)

          Following this, train a simple model, so you have a score that you know can be improved. At this stage, you should just use logistic regression or linear regression (if you are predicting a continuous value)
          Once you train it, save the model as a joblib file named `baseline.joblib`. Take a look at this [link](https://scikit-learn.org/stable/modules/model_persistence.html) to know how to save it
        prerequisites:
          - 89b7fb50-9de8-46a4-bf86-d54cf316b899 # 1 Data for ML
          - 54d541f6-987b-461e-a64b-1c3e76e810c5 # 2 Intro to Models - Linear regression
          - e6991438-bdcd-4170-9e28-a9e7d8ab3569 # 1 Classification
          - 776fec70-0835-4e53-a655-7f83e1aec42a # 2 Multiclass classification
        duration: 8
      - name: Perform feature selection
        id: 1d6fc1a0-3b64-49ba-b429-3a76bd1122b2
        description: |
          This task will focus on the second step of the workflow mentioned in the previous task.
          Feature selection is a process that allows you to select a subset of the features in your dataset. This is useful if you have a lot of features and you don't want to use all of them.
          It's great if you have a model that overfits the data, and you want to reduce the number of features.
          Perform feature selection, so you can use the most important features to train your model.
          You can use LASSO regression for this task, but it's not recommended since it doesn't work very well with multiclass classification. 
          Instead, you can simply take a look at the weights of your features and see which ones are important. Remove those that have low weights and check again the performance. 
          Before you do that, you should check the performance of the model without feature selection on both training and testing sets, and observe if, by removing some features, the metrics on both sets get closer.
          Don't worry if you underfit right now, you will improve your model later.
        prerequisites:
          - ab8dba5e-5bd2-4e09-8d00-32ba8484596c # 3 Validation and Testing
          - 00640ac4-3411-4d51-8618-9d1081b4abaa # 4 Gradient based optimisation
          - a027ad34-762b-46d7-84b4-fe753229c620 # 5 Bias & variance
        duration: 8

      - name: Train and tune other models
        id: bb5b0534-dc35-45db-ba21-37c1587cf3ba
        description: |
          This task will focus on steps 3 to 5 of the workflow mentioned in the first task of this milestone.
          There are many different models that you can use to train your model. You can use KNN, decision trees, random forests... 
          You have to tune them before making a decision, and not the other way around. So first, tune all of them, and then check which one performs better on the testing set.
          Remember not to overfit! Some models, like decision tree, are prone to overfitting, so even if they perform very well on the training set, make sure that it can also perform well on the testing set. If that's the case, you can add different ways of regularisation.
          Once you picked the model, save the model as `model.joblib`.
        prerequisites:
          - 5906e2d6-b031-4f0f-9535-f2558a7a521b # 6 Hyperparameters, Grid Search & K-Fold Cross Validation
          - b097a50c-2ad4-4cdd-8596-38d8d6efca6b # 7 Regularisation
          - da4704d6-1668-4dab-91de-2dad97fa756c # 1 K Nearest Neighbours
          - b0742184-069f-4f88-b78a-d57fda21b08c # 2 Classification Trees
          - 78b30b6a-3a3e-45b8-88e8-1150bb8e2763 # 3 Regression Trees
          - 8c04655f-1322-4192-b307-fbe5a7748de8 # 1 Random forests and Bagging
          - f9eeaba4-7c4b-4182-bb90-8b9f9e99ae50 # 2 Boosting and Adaboost
          - 80233b52-6152-409f-b686-c9cfb9fde3d1 # 3 Gradient Boosting
        duration: 6
      - name: Iteratively train the model with different subsets of the data
        id: 63c10fe3-967c-4e3c-bf35-9a355bc02f39
        description: |
          Take a look at the dataset you have. It comprises data from 1990 to 2020. Do you think getting data from 1990 is representative of the current football data? 
          However, removing the data from 1990 will also leave us with fewer data points. Try to find a balance between having a representative dataset and having a large dataset.
          You can do it by removing some data points from the dataset, and retrain the model with the remaining data.
          On many data science projects, you will use Notebooks to, apart from getting the clean data and training the model, explain the model and explain the results as if you were delivering the product to a customer.
          This is a good time to do it, create a notebook that explains the model you trained and the results you obtained and call it `model_explained.ipynb`.
        duration: 6
      - name: Update your documentation
        id: 0cb1fb21-14d7-449f-b4b2-a86f661c6851
        description: |
          Now that you have trained your model, update your README file with your process for model training.
          Include brief descriptions of the models you used as well as the methods you used for feature selection and give reasons as to why you chose that model.
        duration: 2
    id: a278e285-1dc8-4757-a5d6-94dc36aa7deb

  - name: Inference
    description: |
      With the model that you trained, you can now use it to make predictions. Let's see how many matches you can predict correctly!
    tasks:
      - name: Scrape data of matches that haven't taken place for making predictions
        id: 39963186-a4a0-4223-a134-8a399875e517
        description: |
          This task will scrape data of matches that haven't taken place for making predictions.
          Maybe when you are going through this task, there are no matches available, so instead, use the datasets included in the following files:
          - [Results](https://aicore-files.s3.amazonaws.com/Data-Science/Results.zip)
          - [To Predict](https://aicore-files.s3.amazonaws.com/Data-Science/To_Predict.zip)
          `Results.zip` contains the results of matches that have already taken place right before the matches that haven't taken place yet with the same format as you have seen in the previous datasets.

          `To_Predict.zip` contains the results of matches that haven't taken place yet. You can see that these csv files do not contain the result, since it's the column you will have to predict.

          Save the whole data of `Results.zip` into a single csv called `results_for_prediction.csv`.
        duration: 2
      - name: Use the pipeline you created to clean the scraped data
        id: 0956c671-8abf-42cb-b8f9-ce8c61baaacf
        description: |
          The data you scraped needs to be cleaned. The pipeline you created should be used to clean the data.
          The cleaned data should be saved as `cleaned_results.csv`
          After going through the pipeline, you will be able to get the same features you used for training the model and put the in the files of `To_Predict.zip`.
          Save the csv files with the new features as `to_predict.csv`.
        duration: 6 # hours (1.5 days)
      - name: Use the model to predict the results of the next matches
        id: 94f5a0e6-90eb-477f-a138-ba167666a1d9
        description: |
          As with the model training, inference can be done in a notebook.
          Create the notebook to give explanations of the model and the results of the predictions, and name the notebook `model_results.ipynb`.
        duration: 2
      - name: Update your documentation
        id: a1081f0d-0951-427e-a6e1-58ab2948f251
        description: |
          Update your README file with what you have done for this milestone.
          Don't forget to include the conclusions you have drawn from the models performance and how you would improve the model/data.
          Go back over your entire documentation to make sure everything is clear, concise and reads well.
        duration: 2
    id: 3799b985-70f3-4891-8873-998d5fd7ad1b

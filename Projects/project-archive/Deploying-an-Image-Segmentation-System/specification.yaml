name: Deploying an image segmentation system
description: |
  Image segmentation is the problem of identifying not only which objects are where, but exactly which pixels everywhere in the image belong to each detected instance.

  This is an implementation of a simple system that you might be required to build at a small company that wants to enable employees to access a service for image segmentation.
id: 1c095112-274b-4ad7-a8bc-45720019bfaa
requires_aws: True
requires_github: True
milestones:
  - name: Set up the environment
    tasks:
      - name: Set up Github
        id: 032dcdb6-69e1-450c-96aa-819a45d6ada1
        description: |
          In this project, you'll use GitHub to track changes toyourcode and save them online in a GitHub repo. Hit the button on the right to automatically create a new GitHub repo. We'll tell you when you need to use it as you go through the project.
        duration: 1
        prerequisites:
          - 86076c6d-6df5-4c14-8f5e-7d3dfe661de6
          - b457ee87-74b7-414d-bbc8-43fb8acc8cc4
      - name: Set up AWS
        id: 332dcdb6-69e1-450c-96aa-819a45d6aea2
        description: |
          In this project, we'll use some services running in the cloud. Hit the button on the right to automatically create a new AWS cloud account. We'll tell you when we need to use it as we go through the project.
        duration: 0
    description: Let's set up your dev environment to get started
    id: 393ccbbd-0d50-40df-9fc8-42c49438da41
  - name: Familiarise yourself with the cloud infrastructure, data, and machine learning model
    description: |
      As a first step, it's important to understand the system that you're working with. 
      Here, you will check out the cloud infrastructure that receives requests from your users, the data that they send, and the model that will process them.
    id: 97e20d89-4943-4331-9075-93e0a341000d
    tasks:
      - name: Get an overview of the system in this video
        description: Watch this short video
        id: a74b54ba-38bb-4b91-8668-4c452b556e11
        type: video
        video_url: https://www.youtube.com/embed/hjc4BLlruL0
        duration: 1
      - name: Check out the requests users are sending to your system
        id: 6cb98012-99d5-4dab-82c7-3ba61f1e9aac
        description: |
          Open up the in-Portal terminal and run `sudo nc -lk 8000`. 

          This command listens for information being sent to a particular "port" of your computer (port 8000).
          You should see that every few seconds, users are making requests to this port. 

          They are sending you images that they need you to perform image segmentation upon!

          The image has been encoded and provided as a string, so you will have to decode it throughout the next task.

          Stop the command from running by hitting CTRL+C.
        prerequisites:
          - cf55cfa3-05a2-4299-bd39-ba5acfc9df85 # 1 What is the command line
          - ce694fff-62f7-43fd-b8c9-1c3d9c19c778 # 3 The in-Portal Terminal
          - 7e0fc1d3-42ad-420f-ad7f-4e5b1359233d # 2 Running terminal commands
        duration: 1

      - name: Run the API
        id: f65ab939-e4a3-4090-aa60-66ed53991941
        description: |
          Open the file called `api.py` using `nano` or `vim`. So for example, if you are using `nano`, you can open the file using `nano api.py`.

          This file runs some code that listens for the same requests that you saw in the terminal previously.

          However, the fact that it's written in Python makes it easy to wrap extra functionality around the data in the request.

          The main function named `process_input` is called on the same request data that we saw in the terminal. Don't worry about the code surrounding the function, just focus on adding functionality to it.

          Within `process_input`, there are already two variables that will come very handy: 

          `image_name`, which is the name of the received image in the format xxxx.png (for example, 000007345.png) 

          `image`, which is the byte string of the image that was received.

          Inside the function, add a print statement to print the `image_name`

          Run `api.py` using `python3 api.py` to check that you can see the name of the images that you are receiving.
        prerequisites:
          - 7e0fc1d3-42ad-420f-ad7f-4e5b1359233d # 2 Running terminal commands
          - 1a9545ea-2616-4ef9-bedc-d1d0186c14b5 # 5 Running Python files from the terminal
        duration: 1

      - name: Decode the image
        id: c8d2e785-04c2-4b3d-8c5c-0e93cd6631a9
        description: |
          As mentioned, the information you are receiving is a string of bytes, but you will need to decode it before you can use it.

          In the same `api.py` file you will find a function called `decode_image`.

          Call `decode_image` on the value of the image key from the request body send to the API to decode the image from a base64 encoding into an image that can be both observed and processed.

          Assign the result to a variable called `decoded_image`.

          Print the `size` of the image (`decoded_image.size`).

          Run the `api.py` file from the terminal to ensure that everything works.
        prerequisites:
          - 1a9545ea-2616-4ef9-bedc-d1d0186c14b5 # running python files from the terminal
        duration: 1

      - name: Save the input image to the cloud
        id: 32699ae4-5d65-48ea-9411-1077cb4a4bbc
        description: |
          You will have an S3 bucket (a cloud file storage service hosted by Amazon Web Services) at your disposal.

          This S3 bucket will store the images you receive and the images you will process in the next milestones.

          You will need to use the name of the bucket, to get it, run `aws s3 ls` in the In-Portal terminal.

          In the same `api.py` file you will find a function called `save_image_to_s3`.

          This function will save images to S3. It takes in 3 arguments:

          1. The first is the decoded image
          2. The second is the name that you want to give to the image when saved to S3.
          3. The third is the name of the bucket that you want to save the image to.

          Save this image with the name `input.png` within a folder that has the name as the image.

          That means that the final image should be saved in a folder that looks something like `xxxx/input.png`

          Once the image is succesfully uploaded, you will get a message given by the `save_image_to_s3` function.

          Run the `api.py` file so that at least one image is saved and then stop the program.
        prerequisites:
          - 1a9545ea-2616-4ef9-bedc-d1d0186c14b5 # 5 Running Python files from the terminal
          - a5378de1-4913-409c-bbbb-277a23f2a5f5 # 11 Calling Python functions
        duration: 1

      - name: Take a look at some of the images in S3
        id: 19b54de2-c555-472c-9124-9db33834f23d
        description: |
          Hit the AWS button and then use your AWS credentials to log into the AWS console. 

          In the searchbar, type S3.

          Find and open the S3 bucket that you saved the data to.

          If things worked correctly, you should see the file containing the image you saved.

          Download the image, take a look at it, and ensure that it looks ok.
        prerequisites:
          - f0379838-450b-4d9e-8cf2-4b9178abe37e # 1 S3 and boto3
        duration: 1

  - name: Push the image through the pre-trained model
    description: |
      Now that the image is decoded, we can process it by passing it through an image segmentation model.
    id: 80723dd5-89b1-4e97-bf66-d8316bc5a2bd
    tasks:
      # - name: Import the model from model.py
      #   id: 99214c26-c5bb-4073-8e56-cc717d71b698
      #   description: |
      #     The machine learning model is already saved inside the file `model.py` as a variable called `model`.
      #     Firstly, just import that model variable into `api.py`, then run the Python script to check that everything works.
      #   prerequisites:
      #     - f31dfbbe-2092-488c-8d24-20f1e9024b45 # python
      #   duration: 1

      - name: Pass the image data through the segmentation model
        id: b31bd19a-077c-4937-ae5c-f7b219577575
        description: |
          In the same `api.py` file you will find a function called `perform_segmentation`.

          The function will use a pretrained model and perform segmenation on an image. It takes 2 arguments, in the following order:

          1. The first is the model that you want to use to perform segmentation.
          2. The second is the image that you want to perform segmentation on.

          The function returns the segmented image, and it also prints a message to the console when it starts segmenting the image, and another message when it's done.

          The model is already loaded into the `model` variable.

          Save the result returned from the model to a variable named `segmented_image`.

          Run the `api.py` Python script to check that everything works and make sure you can see the model response.
        prerequisites:
          - 1a9545ea-2616-4ef9-bedc-d1d0186c14b5 # running python files from the terminal
          - a5378de1-4913-409c-bbbb-277a23f2a5f5 # calling python functions
        duration: 0

      - name: Interpret the response from the model
        id: 577e9084-0ee5-44fe-811d-4f51fad775ee
        description: |
          The segmented image will be different from the original one. 

          Once you have a segmented image, print out the `size` of the image (`segmented_image.size`).

          Run the Python script to check that everything works and make sure you can see the model response.
        prerequisites:
          - 8d13bcf2-5772-49de-afb2-8e9820234f7d # 16 Variable attributes
        duration: 0

  - name: Explore the resulting images
    description: |
      It's time to check out the results visually.
    id: 06a4bed1-91d5-4d9a-ac4b-02dc60032681
    tasks:
      - name: Save the processed results in the cloud
        id: 957cf2c4-bced-4d30-ac99-02632446c449
        duration: 1
        description: |
          After you've passed the data through the model, call the function `save_image_to_s3` like you did earlier, but this time save the image as `output.png`.

          So the name of the file you are going to save should look like: `xxxx/output.png`

          It should be in the same folder, named after the id of the request, as the `input.png` that you saved earlier.
        prerequisites:
          - 1a9545ea-2616-4ef9-bedc-d1d0186c14b5 # running python files from the terminal
          - a5378de1-4913-409c-bbbb-277a23f2a5f5 # calling python functions

      - name: Check out some of the results
        id: dfc2c5fc-430d-49e2-8472-92063e8af21b
        description: |
          Hit the AWS button and log into the AWS console. 

          Download a few of the output images now stored inside S3 and check them out. 

          You should see that they have been segmented, and show the different classes of objects in the image in different colors.
        duration: 1

  - name: Deploy the model in the cloud and monitor the results using Prometheus
    description: |
      Your application needs to run continuously, so that it can always serve users. 

      Let's deploy it to run continuously in the cloud without needing to be logged in, and then monitor the results on a dashboard.
    id: 8c13828f-fb26-4401-8564-dbc690a3a0ef
    tasks:
      - name: Use `nohup` to run the API in the background
        id: 6e41bf59-99d3-4166-8c60-f907f643ba16
        description: |
          Run the command `nohup python3 api.py &` to run the API in the background. 

          This way, the ML model will continue processing requests even if you turn off your laptop. 

          Computers in the cloud never need to rest.

          If you want to stop that process, you can kill the process running `pkill -f api.py`
        prerequisites:
          - 7e0fc1d3-42ad-420f-ad7f-4e5b1359233d # running terminal commands
        duration: 1

      - name: Check out the dashboard
        id: d30b534f-c9c9-46a4-8012-aefc136b8d07
        description: |
          The server has already been configured to show a dashboard using Prometheus. 

          To check that out you need to get the public IPv4 address of your server. In the In-Portal terminal, run `dig +short myip.opendns.com @resolver1.opendns.com`

          The result should contain 4 numbers, separated by a dot, something like `34.244.102.101`

          Then, visit the following URL: `http://` + the result + `:9090/graph`

          Once inside, you will see the Prometheus dashboard. To check the network traffic, you can click on the `Graph` tab, type `node_network_transmit_bytes_total` in the search box, and then click on the `Execute` button.

          You will see how much data your server is receiving from the outside world.
        duration: 1
# on-finish:
#   - message: |
#       Congratulations! You've completed the scenario, now, you can listen to the requests coming from the users and perform image segmentation. You also got familiar with the AWS infrastructure and Python functions!

#       However, there is a lot more to understand! If you want to be able to create the image segmentation model, know how the API works, or understand how the infrastructure of this scenario was built, click the button below to learn more.
# infrastructure:
#   - A shared S3 bucket that contains example datapoints to read from by docker containers on all instances of this scenario
#   - Some uniquely named S3 bucket for the user to store their data
#   - Workspace EC2 containing the api.py file, model.py file
#   - prometheus and grafana configuration accessible from open internet
#   - Docker container that base64 encodes images and sends them to port 8000 within a JSON dictionary that has at least an id key and an image key

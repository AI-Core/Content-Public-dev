- name: Implement logistic regression from scratch
  id: 2b1c4e27-16e3-4a74-8034-3f624cf9f6fe
  description: |+
    1. Make a new github repo called "Logistic-Regression"
    2. Load in the breast cancer dataset from sklearn
    3. Load it in, split it into train, test and val
    4. Take a look at an example datapoint's features and labels
    5. git commit
    6. outline the skeleton class for your LogisticRegression model
      - Define the method names (but not the body yet - just put `pass` inside). Which will be private methods?
    7. git commit
    8. Write the code for how you will use the model
      - Initialise
      - Fit
      - Predict
      - What arguments will they take?
    9. Check it runs with no errors
    10. git commit
    11. Now fill in the body of the functions
      - Start with the easiest ones
      - Then implement the loss function
      - Leave calculating the gradients until last
      - git commit
    12. Visualise the loss curves for the training and validation sets

- name: Visualise the hypothesis
  id: f22a365b-382d-4dcc-997f-437257a8bf60
  description: |+
    1. Create a new file called hypothesis_visualisation.py
    2. Create a range of 50 numbers which will act as our features
      - This would represent 50 datapoints each with a single feature
    3. Create labels
      - Split the features into two groups at a random value 
      - Initialise a vector of 50 zeros as the labels
      - For those with features above that value, set the label to be '1'
      - Keep the label for the others as zero
    4. Plot the data and check that it looks right?
      - Is this something that a linear model could split?
      - Are the labels at the correct binary values?
    5. Initialise an instance of your from-scratch logistic regression model
    6. Plot it's initial predictions
      - Firstly visualise it as a scatter plot
      - You might need to order the data first if you want to see a line rather than a scatter
    7. Looking at the hypothesis, before fitting the model
    8. Train the model
    9. Visualise the hypothesis
    10. Can you visualise the predictions during each training to see how training evolves?
    11. Bonus: Visualise linear regression predictions during training

- name: log-sum-exp
  id: 312d373c-1022-4ddd-85dd-678ca4cc2f96
  description: |+
    1. What is `log-sum-exp` trick? Check out [this wiki article](https://en.wikipedia.org/wiki/LogSumExp) for more info

- name: Binary smoothing
  id: 3b60d1cd-e3cc-4f1a-b51d-d2689e65a3aa
  description: |+
    1. Try implementing function called `binary_smoothing(labels, alpha)` which, given labels, smooths the targets with `alpha` parameter
    2. Try to explain the numerical phenomena with epsilon (this one is additional and out of the scope of this course, but you might have some fun)


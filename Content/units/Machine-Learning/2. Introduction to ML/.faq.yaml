- question: |
  in what way is SGD a better ML solution than OLS Linear regression, other than the fact that it's computationally cheaper? Ignoring time taken, and assuming that you've properly feature engineered, normalised, shuffled, split data, etc... analytically solving for the minimum error surely is always gonna yield a better model than using an algorithm to "attempt to find the minimum loss" (and almost always just settling on a local minimum that's slightly higher than the analytical solution). If you had an extremely powerful computer, (and time on your hands, where waiting a few hours for a better solution is worth it for a business), wouldn't the preferred method always be linear regression?
  answer: |
    A few reasons come to mind.

    Computing the analytical solution is not just somewhat computationally expensive, it is computationally intractable for large datasets. That means that you can’t compute it. Simply because, the time complexity of the huge matrix you need to invert in the equation for the analytical solution scales cubically with the number of datapoints you have (when using Gauss’s method of elimination).
    Finding the global optima is not necessarily the best parameterisation to solve the problem… it is the best parameterisation for the problem for the data you have. If you find the global minima for this data, your model is likely to overfit.
    In most cases, the (probably) local minima found by SGD is not much worst than the global minima. One reason for this is that the probability of running into a minima along every axis (a true minima rather than a saddle point) becomes exponentially lower as you increase the number of model parameters (the dimensionality of the space you are searching), and as most models these days easily have millions of params, getting stuck in local optima becomes very unlikely. 

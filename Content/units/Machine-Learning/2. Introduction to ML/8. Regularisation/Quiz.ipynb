{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is regularization used for? Select all that apply.\n",
    "\n",
    "- To decrease overfitting ***\n",
    "- To decrease underfitting\n",
    "- To reduce the variance of our model ***\n",
    "- To improve the metrics on the training set\n",
    "- To help our model to better generalize to new data ***\n",
    "- To reduce the difference between the training and validation error ***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following are regularization techniques? Select all that apply.\n",
    "\n",
    "- Early stopping ***\n",
    "- Splitting the data into training and validation sets\n",
    "- Adding a penalty to the loss function such as weight decay ***\n",
    "- Reducing the capacity of the model ***\n",
    "- Increasing the capacity of the model\n",
    "- Using a different dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is weight decay?\n",
    "\n",
    "- A regularization technique used to increase the values of the model weights and biases\n",
    "- A regularization technique used to decrease the values of the model weights and biases ***\n",
    "- A regularization technique used to increase the complexity of our model\n",
    "- A regularization technique used to decrease the complexity of our model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do you implement weight decay?\n",
    "\n",
    "- By adding a term to the loss function that penalizes small weights\n",
    "- By adding a term to the loss function that penalizes the number of weights\n",
    "- By adding a term to the loss function that penalizes large weights ***\n",
    "- By adding a term to the loss function that penalizes the error of the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does early stopping achieve?\n",
    "\n",
    "- It reduces the variance of the model\n",
    "- It reduces the bias of the model\n",
    "- It stops the training process when the model starts to overfit ***\n",
    "- It stops the training process when the model starts to underfit\n",
    "- It iterates through all the combination of hyperparameters to find the best one"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the common norm penalizations? Select all that apply.\n",
    "\n",
    "- L1 regularization (Lasso) ***\n",
    "- L2 regularization (Ridge) ***\n",
    "- L3 regularization (Tasso)\n",
    "- L4 regularization (Tidge)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does L1 regularization achieve?\n",
    "\n",
    "- It increases the values of the data points using the absolute value function\n",
    "- It decreases the values of the data points using the absolute value function\n",
    "- It increases the values of the model weights using the absolute value function\n",
    "- It decreases the values of the model weights using the absolute value function ***\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When would you want to use L1 regularization over L2 regularization? Select all that apply.\n",
    "\n",
    "- When you have a lot of features and want to reduce the number of features used by the model ***\n",
    "- When you need to include all the features in the model but want to reduce the magnitude of the weights\n",
    "- When you want to enforce sparsity in the model weights ***\n",
    "- When you want to achieve a smooth loss function\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When would you want to use L2 regularization over L1 regularization? Select all that apply.\n",
    "\n",
    "- When you have a lot of features and want to reduce the number of features used by the model\n",
    "- When you need to include all the features in the model but want to reduce the magnitude of the weights ***\n",
    "- When you want to enforce sparsity in the model weights\n",
    "- When you want to achieve a smooth loss function ***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When using sklearn, what is the parameter that controls the amount of L1 or L2 regularization?\n",
    "\n",
    "- alpha ***\n",
    "- beta\n",
    "- learning_rate\n",
    "- lambda\n",
    "- early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09a03f703d9594344a2b9942d46f9fa7ca1a719272e47a84f9d4a0d86a51c104"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

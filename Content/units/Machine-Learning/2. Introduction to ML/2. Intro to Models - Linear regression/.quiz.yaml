name: Linear regression
questions:
  - options:
      - correct: false
        option: It should be able to get decent results on most datasets, but maybe
          not the best
      - correct: false
        option: If I want to call it a linear model, I can't fit it on features which
          are not linear transformations of my original data, like some feature squared
      - correct: false
        option: It is a non-parametric model
      - correct: true
        option: It can predict more than one target, for a single example's features
          in one forward pass
      - correct: true
        option: It can predict more than one target, for multiple example's features
          in one forward pass
      - correct: true
        option: It is easy to explain the predictions of the model
      - correct: false
        option: It should not be used for big datasets, because the analytical solution
          is computationally expensive
      - correct: false
        option: It can't overfit to the data, because it is only linear
      - correct: true
        option: There is only one best set of weights and biases (only one global
          optima on the loss function)
      - correct: true
        option: It's a good first model to use to establish a baseline, which we will
          then aim to improve upon
    question: Select everything true about linear regression
  - options:
      - correct: false
        option: m x n
      - correct: false
        option: m^2
      - correct: false
        option: n^2
      - correct: false
        option: m + n + 1
      - correct: true
        option: n + 1
      - correct: false
        option: m + 1
      - correct: false
        option: '1'
    question: If n is the number of features, and m is the number of examples in your
      dataset, how many parameters will a linear regression model, predicting a scalar
      target have?
  - options:
      - correct: false
        option: X is m x n, W is m x n
      - correct: false
        option: X is n x m, W is m x n
      - correct: false
        option: X is m x m, W is n x n
      - correct: false
        option: X is m x n, W is n x m
      - correct: false
        option: X is m x n, W is m x 1
      - correct: true
        option: X is m x n, W is n x 1
    question: 'My model is of the form y\_hat = XW + b

      If my data has n features and m examples, what should be the shapes of my design
      matrix, X, and my weight matrix, W?'
  - options:
      - correct: true
        option: 'Yes'
      - correct: false
        option: 'No'
    question: I only have one feature, and I create a new feature by squaring the
      values of that original feature. I call the two of these features combined a
      matrix called X. If I make a prediction of the form y = Xw + b, am I using a
      linear model?
  - options:
      - correct: false
        option: The mean squared error is easier to compute than the squared error
      - correct: true
        option: The mean squared error loss function can be used as a criterion for
          classification tasks
      - correct: false
        option: The mean squared error loss function should be used as a criterion
          for classification tasks
      - correct: true
        option: The mean absolute error has a minima at the same point as the mean
          squared error in parameter space
      - correct: false
        option: The mean cubed error has a minima at the same point as the mean squared
          error in parameter space
      - correct: true
        option: The mean squared error is commonly abbreviated to the MSE
      - correct: false
        option: The mean absolute error is differentiable everywhere
    question: Mark everything true about loss functions
  - options:
      - correct: true
        option: parameter space
      - correct: false
        option: feature space
      - correct: false
        option: label space
      - correct: false
        option: myspace
    question: The typical loss surface graph is visualised as a surface at some height
      above
  - options:
      - correct: false
        option: parameter space
      - correct: true
        option: feature space
      - correct: false
        option: label space
      - correct: false
        option: outer space
    question: The typical graph of model predictions is visualised as a (hyper)surface
      at some height above
  - options:
      - correct: false
        option: Anything larger than 1000 should be considered as too high of a loss
      - correct: false
        option: A "good" loss value is less than 100
      - correct: false
        option: The only good loss value is zero. Anything larger indicates a bad model.
        reason: It may not be possible for your model to pass through every datapoint, but it might still make useful predictions.
      - correct: false
        option: A loss value equal to zero is not possible when using a linear regression model
      - correct: true
        option: What constitutes a "good" loss value depends on your model requirements
      - correct: false
        option: For the same model, the mean squared error is expected to get larger as the dataset grows
    question: Mark everything true about the loss

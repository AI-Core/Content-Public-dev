# Hyperparameters, K-Fold Cross Validation And Grid Search

- __`[Explain the difference between parameters and hyperparameters]`__

    - For example, the model weights from an equation can be derived using gradient descent optimisation, where we optimize `w` derivating the loss function with respect to `w`
    - However, while you are training a model, you cannot (or shouldn't) change, the optimization algorithm, or the configuration of the model
    - For example, you shouldn't change the learning rate, or the batch size. (Perhaps, but probably not, you can mention that these two hyperparameters can change while training the model, but it might be a bit advanced now)

- Setting the right hyperparameters is important to improve the performance of the model
    - For example, a high learning rate can lead to an underfitted model
    - A low learning rate can lead to a model that takes too long to converge, or even a model that doesn't converge
    - Another example is the number of estimators in a random forest. A higher number of estimators can lead to an overfitted model
    - But a lower number of estimators can lead to an underfitted model

- __`[RUN A DEMO] THE DEMO WILL TRAIN A RANDOM FOREST MODEL WITH DIFFERENT HYPERPARAMETERS`__
    - For example, let's try to train a random forest model with different hyperparameters
    - We will use the `RandomForestClassifier` class from the `sklearn.ensemble` module
    - First we will use a small number of estimators, say for example 5
    - __`[RUN THE CELL WITH 5 ESTIMATORS]`__
    - Notice that the accuracy is around 94%, which is not bad, but not great
    - Let's see what happens if we increase the number of estimators to 100
    - __`[RUN THE CELL WITH 100 ESTIMATORS]`__
    - Awesome! the accuracy is now around 97%, that's a lot better!




- Once you get the best hyperparameters, you can start training the model with these hyperparameters using the whole dataset instead of using test sets
    - This is because we already used cross validation to find the best hyperparameters, and therefore, the resulting model works well on left-out set
    - Also, the amount of samples we have is valuable, so, usually, the more data we use, the better the model

# First example

- Now, let me show you how to create your first kafka broker and store data in a topic

_Switch to screen capture_

_Search for Kafka on browser_

- you can install kafka from the link on the official kafka website

_Go to downloads page_

_Click to the source download_

_Unzip it_

- within the folder we've just unzipped, is the kafka source code
- it includes shell scripts defining terminal commands which we will use to control kafka

_Switch to webcam_

- note that, I'm just running everything on one machine
- in industry, you'd have a cluster of machines networked together
- and that cluster would most likely already have been set up by other software engineers

- now we've got the kafka source code, the first thing we need to do is to start zookeper, which is a software used in several apache projects, that is going to coordinate each of our brokers in the cluster
- you should also note that in the future kafka will be able to run without zookeeper

_Run `bin/zookeeper-server-start.sh config/zookeeper.properties`_

- now, we can start a broker which is going to store our events by running the kafka server start, and give it the argument which contains the server properties

_Run `bin/kafka-server-start.sh config/server.properties`_

- note that at the moment, I'm only going to be able to access these shell scripts, which are the kafka commands, from within this folder
- if I wanted to avoid needing to write the full filepath, then I could add this folder to my system path environment variable

- no we've got a broker running, we should create a topic to send data to

- let's say we didn't know how to do this
- i dont expect you to know, and I don't expect myself to remember
- but i do expect you to be able to find out using the docs
- let's check them out

_Go to kafka site and click docs_

<!-- TODO these docs suck major. Surely there's a better place that actually explains the different keyword arguments etc -->

- ok so I'm looking for topic docs

- Here it is on the left under configuration

_Click topic configs_

- you can see a bunch of examples here for how to configure topics

- the command requires a few things
  - a hostname and port
  - the create option
  - the topic name
  - the number of partitions
  - the replication factor, which is how many times the data will be replicated for robustness in case one of the nodes is lost

name

_Run `bin/kafka-topics.sh --create --topic MyFirstKafkaTopic --partitions 1 --replication-factor 1 --bootstrap-server localhost:9092`_

- now we've got a topic, we can create kafka producers to publish events to the topic
- and we can create kafka consumers which will pull events off of the topic

- so i'm goign to check out the producer docs

_Run `./kafka-console-producer.sh --topic MyFirstKafkaTopic --bootstrap-server localhost:9092`_

- now I will create a consumer to consume data sent from that topic

_Run `kafka-console-consumer.sh --topic MyFirstKafkaTopic --from-beginning --bootstrap-server localhost:9092`_

_Show producer sending message to consumer_

- I can create many connected producers, topics, and consumers
<!-- - and consumer subscribed to a topic will recieve the events sent to it -->

_Show creating more topics, producers and consumers_

- now what I could do, would be to perhaps redirect this console output to the relevant data destination or to another command
- or I could use the kafka bindings for java or python to pass that onto another piece of the system

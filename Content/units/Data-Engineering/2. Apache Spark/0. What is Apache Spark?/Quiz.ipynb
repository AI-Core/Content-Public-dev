{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Apache Spark?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following is true about Apache Spark?\n",
    "\n",
    "- A) Spark is a distributed computing system for processing big data ***\n",
    "- B) Spark can only be used with the Hadoop Distributed File System (HDFS)\n",
    "- C) Spark is a relational database management system\n",
    "- D) Spark is primarily used for transactional processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following statements are true about Apache Spark?\n",
    "\n",
    "- A. Spark is a distributed computing system for processing large amounts of data\n",
    "- B. Spark supports multiple programming languages such as Python, Java, and Scala\n",
    "- C. Spark provides high-level APIs for machine learning and graph processing\n",
    "- D. Spark is designed to run only on a single machine\n",
    "\n",
    "Select all the correct answers:\n",
    "- a) A and B\n",
    "- b) A, B, and C ***\n",
    "- c) B and C\n",
    "- d) A, C, and D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following statements is false about Apache Spark?\n",
    "\n",
    "- A) Spark is a distributed computing system for processing large amounts of data\n",
    "- B) Spark provides APIs for machine learning and graph processing\n",
    "- C) Spark can only be used with the Hadoop Distributed File System (HDFS) ***\n",
    "- D) Spark supports multiple programming languages such as Python, Java, and Scala"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following are key features of Apache Spark?\n",
    "\n",
    "- A. In-memory computing\n",
    "- B. Fault-tolerance\n",
    "- C. Ease of use and compatibility with multiple programming languages\n",
    "- D. Batch processing only\n",
    "\n",
    "Select all the correct answers:\n",
    "- a) A, B, and C ***\n",
    "- b) B and D\n",
    "- c) A and D\n",
    "- d) A, B, C, and D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following programming languages are officially supported by Apache Spark?\n",
    "\n",
    "- A. Python\n",
    "- B. Java\n",
    "- C. Scala\n",
    "- D. Ruby\n",
    "\n",
    "Select all the correct answers:\n",
    "- a) A, B, and C ***\n",
    "- b) A, B, C, and D\n",
    "- c) A and C\n",
    "- d) B and D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following cluster managers can be used with Apache Spark?\n",
    "\n",
    "- A. Apache Hadoop YARN\n",
    "- B. Apache Mesos\n",
    "- C. Spark Standalone\n",
    "- D. All of the above\n",
    "\n",
    "Select the correct answer:\n",
    "- a) A and C\n",
    "- b) B and C\n",
    "- c) A, B, and C\n",
    "- d) D ***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following statements is true about Spark clusters?\n",
    "\n",
    "- A. A Spark cluster is a group of interconnected computers that work together to process large datasets in a distributed and parallel manner\n",
    "- B. Spark clusters are limited to a single data center\n",
    "- C. Spark clusters require a dedicated network infrastructure to function properly\n",
    "D. Spark clusters can only be managed by the Spark Standalone cluster manager\n",
    "\n",
    "Select the correct answer:\n",
    "- a) A ***\n",
    "- b) B and C\n",
    "- c) A and D\n",
    "- d) A, B, and C"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Spark driver?\n",
    "\n",
    "- A) The Spark driver is the part of the Spark application that runs on the worker nodes and performs the actual data processing\n",
    "- B) The Spark driver is a process that runs the main() function of the Spark application and coordinates the execution of tasks on the cluster ***\n",
    "- C) The Spark driver is a component that manages the storage and retrieval of data in Spark\n",
    "- D) The Spark driver is a cluster manager that is responsible for allocating resources to Spark applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following is a function of a Spark cluster manager?\n",
    "\n",
    "- A) Allocating resources to Spark applications ***\n",
    "- B) Running the main() function of the Spark application \n",
    "- C) Coordinating the execution of tasks on the worker nodes\n",
    "- D) Performing the actual data processing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the SparkSession?\n",
    "\n",
    "- A) The SparkSession is the entry point to programming Spark with the Dataset and DataFrame API ***\n",
    "- B) The SparkSession is a component of the Spark cluster manager\n",
    "- C) The SparkSession is responsible for allocating resources to Spark applications\n",
    "- D) The SparkSession is the part of the Spark application that performs the actual data processing\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is `spark-submit` in Apache Spark?\n",
    "\n",
    "- A) `spark-submit` is a command-line tool used to start the Spark driver program for a Spark application by submitting the Spark application code to a cluster\n",
    "- B) `spark-submit` is a component of the Spark cluster manager used to allocate resources to Spark applications\n",
    "- C) `spark-submit` is a Spark package used to interface with external data sources\n",
    "- D) `spark-submit` is a web-based graphical user interface used to monitor and manage Spark applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Spark Application in Apache Spark?\n",
    "\n",
    "- A) A Spark Application is a standalone application that runs on the Spark cluster and performs data processing tasks ***\n",
    "- B) A Spark Application is a component of the Spark cluster manager used to manage the resources allocated to Spark applications\n",
    "- C) A Spark Application is a Spark package used to interface with external data sources\n",
    "- D) A Spark Application is a web-based graphical user interface used to monitor and manage Spark applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the main difference between local, standalone, Mesos, and YARN cluster managers in Apache Spark?\n",
    "\n",
    "- A) The number of worker nodes supported by each cluster manager\n",
    "- B) The programming languages supported by each cluster manager\n",
    "- C) The amount of resources and scheduling capabilities provided by each cluster manager ***\n",
    "- D) The level of fault tolerance and scalability provided by each cluster manager"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Spark executor in Apache Spark?\n",
    "\n",
    "- A) A Spark executor is a node on the Spark cluster that runs tasks for a Spark application ***\n",
    "- B) A Spark executor is a component of the Spark cluster manager used to manage the resources allocated to Spark applications\n",
    "- C) A Spark executor is a Spark package used to interface with external data sources\n",
    "- D) A Spark executor is a web-based graphical user interface used to monitor and manage Spark applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is MapReduce in Hadoop?\n",
    "\n",
    "- A) MapReduce is a programming model and software framework for processing large datasets in parallel across a Hadoop cluster ***\n",
    "- B) MapReduce is a distributed storage system that provides high-throughput access to data stored on Hadoop Distributed File System (HDFS)\n",
    "- C) MapReduce is a command-line interface tool used to manage and monitor Hadoop clusters\n",
    "- D) MapReduce is a distributed coordination service used to manage and synchronize the execution of Hadoop jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the main steps involved in a MapReduce job?\n",
    "\n",
    "- A) Map, Filter, Reduce\n",
    "- B) Load, Shuffle, Merge\n",
    "- C) Split, Map, Reduce ***\n",
    "- D) Input, Output, Storage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens if a task fails in a MapReduce job?\n",
    "\n",
    "- A) The MapReduce job fails and the entire job needs to be restarted from scratch\n",
    "- B) The MapReduce framework automatically retries the failed task a fixed number of times ***\n",
    "- C) The failed task is skipped and the MapReduce job continues with the remaining tasks\n",
    "- D) The output of the failed task is ignored and the MapReduce job continues with the remaining tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the main difference between Spark and Hadoop?\n",
    "\n",
    "- A) Hadoop is a distributed storage system, while Spark is a distributed data processing system ***\n",
    "- B) Hadoop is a batch processing system, while Spark is a real-time processing system\n",
    "- C) Hadoop is written in Java, while Spark is written in Scala\n",
    "- D) Hadoop and Spark are interchangeable and can be used interchangeably in all use cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is data locality in Spark and why is it important for Spark performance?\n",
    "\n",
    "- A) Data locality refers to the physical location of the data on the disk, and it is important for Spark performance because it minimizes the network traffic between the nodes in the cluster ***\n",
    "- B) Data locality refers to the logical location of the data in the application code, and it is important for Spark performance because it allows for faster data access and processing\n",
    "- C) Data locality refers to the number of times the data is accessed in the Spark job, and it is important for Spark performance because it reduces the amount of data that needs to be processed\n",
    "- D) Data locality refers to the size of the data in the Spark job, and it is important for Spark performance because it reduces the amount of data that needs to be processed"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Essentials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the correct syntax to read a CSV file in PySpark?\n",
    "\n",
    "- A) `df = spark.read.csv(\"path/to/file.csv\")`\n",
    "\n",
    "- B) `df = spark.read.csv(\"path/to/file.csv\")` ***\n",
    "\n",
    "- C) `df = sqlContext.read.csv(\"path/to/file.csv\")`\n",
    "\n",
    "- D) `df = spark.read.text(\"path/to/file.csv\")`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the correct syntax to display the contents of a PySpark DataFrame in the console?\n",
    "\n",
    "- A) `df.print()`\n",
    "\n",
    "- B) `df.show()` ***\n",
    "\n",
    "- C) `df.display()`\n",
    "\n",
    "- D) `df.printSchema()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the correct syntax to display a PySpark DataFrame with headers in the console?\n",
    "\n",
    "- A) `df.show()`\n",
    "\n",
    "- B) `df.head()`\n",
    "\n",
    "- C) `df.display(header=True)`\n",
    "\n",
    "- D) `df.display(header=True)` ***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the correct syntax to aggregate by column in PySpark?\n",
    "\n",
    "- A) `df.agg(sum(\"column_name\"))`\n",
    "\n",
    "- B) `df.groupby(\"column_name\").sum()`\n",
    "\n",
    "- C) `df.groupby(\"column_name\").agg(sum(\"column_name\"))`\n",
    "\n",
    "- D) `df.groupBy(\"column_name\").agg({\"column_name\": \"sum\"})` ***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the correct syntax to group a PySpark DataFrame by a specific column?\n",
    "\n",
    "- A) `df.groupBy(\"column_name\")` ***\n",
    "\n",
    "- B) `df.group(\"column_name\")`\n",
    "\n",
    "- C) `df.aggregateBy(\"column_name\")`\n",
    "\n",
    "- D) `df.groupby(\"column_name\")`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the correct syntax to count the number of entries in a PySpark DataFrame column?\n",
    "\n",
    "- A) `df.count(column_name)`\n",
    "\n",
    "- B) `df.count(column_name)` ***\n",
    "\n",
    "- C) `df.select(count(\"column_name\")).show()`\n",
    "\n",
    "- D) `df.column_name().count()`\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

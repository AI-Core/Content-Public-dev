# Aggregations

## Setup

### What do i need open?

- You will need to open pgAdmin4, and if you have it, open the Pagila database. Otherwise, the file can be foung in the SQL Setup lesson
- OBS
    
### What recording scenes do I need open?

- Screencapture of pgAdmin4 with your webcam capture in the corner
- Webcam capture in full screen

## Script

- __`[START SCENE] webcam in full screen`__
    - SQL doesn't just allow you to make queries for creating, reading, updating, or deleting data. It also allows you to analyze that data.
    - For example, you can use SQL to quickly find the total amount of money made by each store.
    - Or the average amount of time each customer rented a film
    - These operation are called aggregations.
    - There are a lot of different aggregation functions, so make sure to check the documentation. 
    - Here, we are going to check some of the most common aggregation functions: count, sum, average, minimum, and maximum.
    - We will also use the `GROUP BY`, which will allow us to see the aggregated results for each group
    - Let's go to pgAdmin4 to check some examples using aggregations.

<br>

- __`[CHANGE SCENE] Open pgAdmin4`__
    - Let's open the Pagila database __`[CLICK THE QUERY TOOL IN THE PAGILA DATABASE]`__
    - For this example, we are going to take a look at the rental and payment tables. First, let's check the columns in the table:
    ```
    SELECT * FROM rental;
    ```
    - There is a column named return_date, which is the date the customer returned the film.
    - If the customer didn't return the film, the return_date will be null.
    - Let's check how many customer didn't return the film:
    ```
    SELECT * FROM rental
    WHERE return_date IS NULL;
    ```
    - Let's scroll down to the bottom to see how many occurences there are __`[SCROLL DOWN]`__  We can see that there are 183 films that were not returned.
    - We can also use the `COUNT` function to count the number of occurences of a value:
    ```
    SELECT COUNT(*) FROM rental
    WHERE return_date IS NULL;
    ```
    - And it directly shows us the number of films that were not returned: 183
    - In this case, we use an asterisk to count the number of rows in the table, but if we use this function with a column, COUNT will ignore the null values.
    - Let's use the `COUNT` function to count the number of rented films:
    ```
    SELECT COUNT(rental_date) FROM rental;
    ```
    - We obtained 16044 occurences. Now, let's check the number of films that were returned:
    ```
    SELECT COUNT(return_date) FROM rental;
    ```
    - In this case, we obtained 15861 occurences, which is the number of rented films minus the number of films that were not returned.
    - So there you have it, you can see that COUNT doesn't take into account the null values for the final count
    - Let's check the following aggregation functions, max and min.
    - As their names suggest, they return the maximum and minimum values of a column.
    - Depending on the data type of the column, the way they sort the values can be different. 
    - For example, if you have a column with integers, the max function will return the highest value. 
    - If you have a column with dates, max will return the latest date.
    - Or if you have a column with strings, max will sort the column alphabetically.
    - Let's check when was the most recent rental:
    ```
    SELECT MAX(rental_date) FROM rental;
    ```
    - The latest rental date was on the 14th of February, 2006, this database sure is old!
    - Let's check when was the first rental:
    ```
    SELECT MIN(rental_date) FROM rental;
    ```
    - The first rental date took place on the 24th of May, 2005
    - Let's move on to the film table, and check the maximum title, so to speak:
    ```
    SELECT MAX(title) FROM film;
    ```
    - The maximum is "ZORRO ARK", which makes sense, since it starts with the letter Z, and as mentioned, the max function sorts the column alphabetically.
    - Let's use the payment table now, so we can explain the other two aggregation functions: sum and average.
    - Let's first check the columns in the table:
    ```
    SELECT * FROM payment;
    ```
    - Let's focus on the amount column, which is the amount of money that was paid in the transaction.
    - Let's see the total amount of money paid:
    ```
    SELECT SUM(amount) FROM payment;
    ```
    - As you can see, we obtain a total of 67416.51
    - Let's see the average amount of money paid:
    ```
    SELECT AVG(amount) FROM payment;
    ```
    - The average amount of money paid is 4.2
    - So, you can see that using aggregation functions on a single column is fairly simple. Let's spice things up and use the `GROUP BY`.
    - For example, what if we wanted to see the total amount of money paid in each store?
    - We can use the `GROUP BY` to group the results by a column, and then use the aggregation functions to get the total amount that each staff member charged:
    ```
    SELECT staff_id, SUM(amount) FROM payment
    GROUP BY staff_id;
    ```
    - Notice that, as opposed to earlier, we obtain two rows instead of one. The way GROUP BY works is that it sees all the unique values in the column we specified, and then performs the aggregation function on each group.
    - So in this case, we only have two staff members, it takes all the payments charged by each staff member, and then it calculates the average on each group.
    - What is we wanted to see more columns in the results?
    - Let's add more columns to it:
    ```
    SELECT staff_id, rental_id, AVG(amount) FROM payment
    GROUP BY staff_id;
    ```
    - Oh no, we have an error! The problem is that we are not groupin by the rental_id column. Think about it, we are calculating the average amount per staff member by grouping the staff members on their unique values, so how is SQL going to show the rental_id as well?
    - We can add more columns to the GROUP BY statement if we wanted to see more columns in the results:
    ```
    SELECT staff_id, rental_id, AVG(amount) FROM payment
    GROUP BY staff_id, rental_id;
    ```
    - In this case we obtain many more rows than before. The reason is that we are grouping by unique combinations of staff_id and rental_id, so essentially, we are getting all the payments that were made by each staff member for each rental.
    - Let's see more examples to make sure you understand the GROUP BY statement.
    - Let's see the total money spent by each customer:
    ```
    SELECT customer_id, SUM(amount) FROM payment
    GROUP BY customer_id;
    ```
    - We obtained 599 rows, which is the total number of customers.
    - Let's say that we want to see the total amount spent by each customer for each rental, only if the payment was made after the 1st of May, 2007.
    - We could use a WHERE clause to filter the results, right?
    ```
    SELECT customer_id, SUM(amount) FROM payment
    GROUP BY customer_id
    WHERE payment_date > '2007-05-01';
    ```
    - What happened? Why are we getting an error? The problem is the way operations are performed in SQL.
    - The first operation is FROM, so we know where to get the data from.
    - The second operation should be WHERE, so we can filter from the whole table.
    - But here we are performing the GROUP BY first, so WHERE is trying to filter the output of the GROUP BY, which, for SQL doesn't make sense.
    - So, if we wanted to use the WHERE statement, we have to use the WHERE before the GROUP BY:
    ```
    SELECT customer_id, SUM(amount) FROM payment
    WHERE payment_date > '2007-05-01'
    GROUP BY customer_id;
    ```
    - Success! You can check that the filter was applied because now we have 158 rows instead of 599.
    - Ok, so we know that we can apply a filter before the GROUP BY, but what if we wanted to apply a filter to the output of the GROUP BY?
    - We just saw that we can't apply WHERE after the GROUP BY
    - In such cases, we can use the HAVING clause
    - For example, let's see only the customers who spent more than 150:
    ```
    SELECT customer_id, SUM(amount) FROM payment
    GROUP BY customer_id
    HAVING SUM(amount) > 150;
    ```
    - Great! All the values in the second column are greater than 150
    - We are going to take a look now at some functions that can be very helpful, especially when working with dates. I am talking about DATE_TRUNC and DATE_PART
    - `DATE_TRUNC` is a function that truncates a date to a certain unit of time. For example, let's check the payment date in the payment table:
    ```
    SELECT payment_date FROM payment;
    ```
    - Notice that the format is Years-Months-Days Hours, Minutes, and Seconds. You can use DATE_TRUNC to truncate this date to the day:
    ```
    SELECT DATE_TRUNC('day', payment_date) FROM payment;
    ```
    - Now the dates in the output have the hours, minutes and seconds all set to 0.
    - So, you might be wondering why we want to get the dates truncated.
    - Let's see what happens when we use GROUP BY with the date as it was
    - Let's say for example, that we want to see the total amount of money spent per day:
    ```
    SELECT payment_date, SUM(amount) FROM payment
    GROUP BY payment_date;
    ```
    - Huh, we are getting almost the same number of rows as the original table
    - As mentioned, GROUP BY groups the values of a column on unique values
    - However, when dealing with dates, it is very unlikely that two dates are the same because in this case they consider the seconds as well
    - So, if we use DATE_TRUNC to truncate the date, we can have all the transactions made on the same day with the same value.
    - So, let's repeat the example, but this time, truncating the date to the day:
    ```
    SELECT DATE_TRUNC('day', payment_date), SUM(amount) FROM payment
    GROUP BY 1;
    ```
    - Much better! Now we get only a row per day.
    - By the way, what do you think the 1 in GROUP BY means? __`[Make a pause]`__
    - It is the position of the column we want to group by, so we don't have to rewrite the whole statement for referencing the column.
    - DATE_TRUNC can also truncate the date to the year, month, hour...
    - For example, let's truncate see the spending per month:
    ```
    SELECT DATE_TRUNC('month', payment_date), SUM(amount) FROM payment
    GROUP BY 1;
    ```
    - We simply changed the first argument of DATE_TRUNC to 'month' and that's it!
    - The other helpful function for dealing with dates is DATE_PART
    - DATE_PART is a function that returns the value of a date in a certain unit of time.
    - It essentially extracts a certain value from a date, for example, year, month, day, hour, minute, second, etc.
    - Let's see how we can use DATE_PART to get the month of the payment date:
    ```
    SELECT DATE_PART('month', payment_date) FROM payment;
    ```
    - Notice that, as opposed to DATE_TRUNC, DATE_PART returns a single value.
    - You can also extract the day of the week using the `DOW` argument. Let's see the average spending per day of the week:
    ```
    SELECT DATE_PART('dow', payment_date), SUM(amount) FROM payment
    GROUP BY 1;
    ```
    - The output shows 7 rows, one for each day of the week, where 0 corresponds to Sunday and 6 corresponds to Saturday.
    - So you can see that the days where people spend the most are Monday and Friday
    - To finish off, let's take a look at some functions that are not related to aggregations, but are very useful
    - Let's take a look at DISTINCT, and CASE
    - DISTINCT is a function that returns the distinct values of a column
    - For example, we can see the distinct values of the staff_id column in the payment table:
    ```
    SELECT DISTINCT staff_id FROM payment;
    ```
    - Only two values are returned, 1 and 2, don't worry, it is not an error!
    - If we add more columns, there is no problem, we get the unique values of the combination of all the columns
    - So, for example, let's see the unique values that each staff member has made a payment for:
    ```
    SELECT DISTINCT staff_id, amount FROM payment;
    ```
    - You can see that we have 35 rows, one for each unique combination of staff_id and amount
    - Let's take a look now at the CASE function
    - CASE is a function that returns a value based on a condition
    - It would be the equivalent of an if-else statement in Python
    - CASE goes after the SELECT statement, but before the FROM statement, so you can treat it as another column that SELECT picks up
    - The syntax is as follows:
    ```
    SELECT column_name,
    CASE
        WHEN condition1 THEN value1
        WHEN condition2 THEN value2
        ...
        ELSE valueN
    END AS alias
    FROM table_name;
    ```
    - So, if condition1 holds, the value in the column corresponding to the one returned by the CASE statement is value1, if condition1 doesn't hold but condition2 does, the value is value2, and so on.
    - If none of the conditions hold, the value is the one in the ELSE clause
    - Let's say that we want to check if a payment was done in the morning, in the afternoon, in the evening, or during the night.
    - We can use CASE to check that:
    ```
    SELECT payment_date, 
    CASE
        WHEN DATE_PART('hour', payment_date) BETWEEN 6 AND 12 THEN 'Morning'
        WHEN DATE_PART('hour', payment_date) < 18 THEN 'Afternoon'
        WHEN DATE_PART('hour', payment_date) < 21 THEN 'Midnight'
		ELSE 'Night'
    END AS time_of_day
    FROM payment;
    ```
    - Nice! We can see that the second column has only 4 different values based on the hour of the day.


<br>

- __`[CHANGE SCENE] webcam in full screen`__
    - Analyzing the data is a very important step when working in any project.
    - You learned how to make use of SQL aggregations to get some simple insights into the data.
    - More specifically, you learned how to use count, sum, min, max, and average, to get some basic statistics.
    - Then I showed you how to group some the values in a column and return the aggregated values in those groups.
    - You also saw how to deal with dates using DATE_TRUNC and DATE_PART.
    - And finally, we visited some functions that are useful such as DISTINCT and CASE.
    - Now, you not only know how to retrieve data from a table, but you also know how to analyze it. Way to go!
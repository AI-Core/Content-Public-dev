{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning in Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose you have a pandas DataFrame called `sales_data` with a column called `price` that contains prices in the format `$xx.xx`, where `x` is a digit. You want to convert the `price` column to a numerical data type while keeping the exact price. Which of the following code snippets will achieve this?\n",
    "\n",
    "- A) ***\n",
    "``` python\n",
    "sales_data[\"price\"] = sales_data[\"price\"].str.replace(\"$\", \"\")\n",
    "sales_data[\"price\"] = sales_data[\"price\"].astype(float)\n",
    "```\n",
    "\n",
    "- B)\n",
    "``` python\n",
    "sales_data[\"price\"] = sales_data[\"price\"].astype(float)\n",
    "sales_data[\"price\"] = sales_data[\"price\"].str.replace(\"$\", \"\")\n",
    "```\n",
    "\n",
    "- C)\n",
    "``` python\n",
    "sales_data[\"price\"] = sales_data[\"price\"].astype(int)\n",
    "sales_data[\"price\"] = sales_data[\"price\"].str.replace(\"$\", \"\")\n",
    "```\n",
    "\n",
    "- D)\n",
    "``` python\n",
    "sales_data[\"price\"] = sales_data[\"price\"].str.replace(\"$\", \"\")\n",
    "sales_data[\"price\"] = sales_data[\"price\"].astype(int)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose you have a pandas DataFrame called `sales_data` with a column called `region` that contains the regions where sales were made. The `region` column has a small number of unique values compared to the total number of rows in the DataFrame. What data type should the `region` column be to optimize memory usage?\n",
    "\n",
    "- A) `int`\n",
    "- B) `bool`\n",
    "- C) `string`\n",
    "- D) `category` ***\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose you have a pandas DataFrame called `employee_data` with a column called `employee_id` that contains unique identifiers for each employee. You want to find all the rows with duplicate employee IDs in the DataFrame. Which of the following code snippets will achieve this?\n",
    "\n",
    "- A) `employee_data[employee_data[\"employee_id\"].duplicated()]` ***\n",
    "- B) `employee_data.duplicated(subset=\"employee_id\")`\n",
    "- C) `employee_data[employee_data.duplicated(\"employee_id\")]`\n",
    "- D) `employee_data[\"employee_id\"].duplicated()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose you have a pandas DataFrame called `sales_data` with columns `date` and `sales_amount`. You want to sort the DataFrame in ascending order based on the `sales_amount` column. Which of the following code snippets will achieve this without redundancy?\n",
    "\n",
    "- A) `sales_data.sort_values(\"sales_amount\")`\n",
    "- B) `sales_data.sort_values(by=\"sales_amount\")` ***\n",
    "- C) `sales_data.sort_values(\"sales_amount\", ascending=True)`\n",
    "- D) `sales_data.sort_values(by=\"sales_amount\", ascending=False)`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose you have a pandas DataFrame called `employee_data`. How can you check whether there are any `NaN` values in the DataFrame?\n",
    "\n",
    "- A) `employee_data.isna()` ***\n",
    "\n",
    "- B) `employee_data.isnan()`\n",
    "\n",
    "- C) `employee_data.hasna()`\n",
    "\n",
    "- D) `employee_data.hasnan()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose you have a pandas DataFrame called `sales_data` with columns `date`, `product`, and `sales_amount`. The DataFrame contains some duplicate rows where the same product was sold on the same date. You want to calculate the average sales amount for each product across all duplicate rows. Which of the following code snippets will achieve this?\n",
    "\n",
    "- A) `sales_data.groupby([\"date\", \"product\"])[\"sales_amount\"].mean()` ***\n",
    "- B) `sales_data.groupby([\"date\", \"product\"])[\"sales_amount\"].mean()`\n",
    "- C) `sales_data.groupby([\"product\", \"sales_amount\"])[\"date\"].mean()`\n",
    "- D) `sales_data.groupby(\"date\")[\"product\", \"sales_amount\"].mean()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose you have a pandas DataFrame called `employee_data` with columns `employee_id`, `employee_name`, and `department`. You want to filter the DataFrame to only include rows where the `department colum`n contains either `\"Sales\"` or `\"Marketing\"`. Which of the following code snippets will achieve this?\n",
    "\n",
    "- A) `employee_data.filter(items=[\"Sales\", \"Marketing\"], axis=0)`\n",
    "- B) `employee_data.loc[employee_data[\"department\"] == [\"Sales\", \"Marketing\"]]`\n",
    "- C) `employee_data[employee_data[\"department\"].isin([\"Sales\", \"Marketing\"])]` ***\n",
    "- D) `employee_data[employee_data.isin([\"Sales\", \"Marketing\"])]` "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose you have a pandas DataFrame called `sales_data` with several columns, including a column called `customer_age` that contains the age of each customer. Some of the rows in the DataFrame have missing values in the `customer_age` column. You want to remove all the rows with missing values in the `customer_age` column before analyzing the data. Which of the following code snippets would achieve this goal?\n",
    "\n",
    "- A) `sales_data.dropna('customer_age')`\n",
    "- B) `sales_data.dropna(subset=['customer_age'])` ***\n",
    "- C) `sales_data.dropna(columns='customer_age')`\n",
    "- D) `sales_data.dropna(how='all')`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppose you have a pandas DataFrame called `student_grades` with several columns, including a column called `grade` that contains the grade of each student. Some of the rows in the DataFrame have missing values in the `grade` column. You want to identify all the rows with missing values in the `grade` column. Which of the following code snippets would achieve this goal?\n",
    "\n",
    "- A) `student_grades.isnull('grade')`\n",
    "- B) `student_grades.isnull(subset=['grade'])`\n",
    "- C) `student_grades['grade'].isnull()` ***\n",
    "- D) `student_grades.isnull()`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

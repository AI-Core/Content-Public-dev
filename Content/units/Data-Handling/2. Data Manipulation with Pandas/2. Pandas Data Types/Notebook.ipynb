{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11924f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ### Run the following cell to download the necessary files for this lesson { display-mode: \"form\" } \n",
    "#@markdown Don't worry about what's in this collapsed cell\n",
    "\n",
    "!pip install -q PyYaml\n",
    "print('Downloading Salaries.csv...')\n",
    "!wget https://s3-eu-west-1.amazonaws.com/aicore-portal-public-dev-524288083424/lesson_files/3d1ad53c-8b55-41f0-8772-08c39b437cfb/Salaries.csv -q -O Salaries.csv\n",
    "print('Downloading employees.json...')\n",
    "!wget https://s3-eu-west-1.amazonaws.com/aicore-portal-public-dev-524288083424/lesson_files/3d1ad53c-8b55-41f0-8772-08c39b437cfb/employees.json -q -O employees.json\n",
    "print('Downloading animals.yaml...')\n",
    "!wget https://s3-eu-west-1.amazonaws.com/aicore-portal-public-dev-524288083424/lesson_files/3d1ad53c-8b55-41f0-8772-08c39b437cfb/animals.yaml -q -O animals.yaml\n",
    "print('Downloading employees_2.json...')\n",
    "!wget https://s3-eu-west-1.amazonaws.com/aicore-portal-public-dev-524288083424/lesson_files/3d1ad53c-8b55-41f0-8772-08c39b437cfb/employees_2.json -q -O employees_2.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Once you have imported your data into a `DataFrame`, a common first step is to check the data type (`dtype`) of each column, and adjust any that aren't optimal for your analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Below is a table that shows various `Pandas` data types, their corresponding Python data types, and a brief description of each.\n",
    "\n",
    "| Pandas Dtype | Python Dtype        | Description                                           |\n",
    "|--------------|---------------------|-------------------------------------------------------|\n",
    "| object       | str                 | Used for text or mixed types of data                  |\n",
    "| int64        | int                 | Integer numbers                                       |\n",
    "| float64      | float               | Floating-point numbers                                |\n",
    "| bool         | bool                | Boolean values (True/False)                           |\n",
    "| datetime64   | datetime.datetime   | Date and time values                                  |\n",
    "| timedelta64  | datetime.timedelta  | Differences between two datetimes                     |\n",
    "| category     | (special type)      | Finite list of text values                            |\n",
    "| period       | pd.Period           | Periods of time, useful for time-series data          |\n",
    "| sparse       | (special type)      | Sparse array to contain mostly NaN values             |\n",
    "| string       | str                 | Text                                                  |\n",
    "\n",
    "Note that:\n",
    "\n",
    "- The `int64` and `float64` data types indicate 64-bit storage for integer and floating-point numbers, respectively. `Pandas` also supports other sizes (like `int32` and `float32`) to save memory when the larger sizes are not necessary. An `int` type column cannot contain `NaN` values.\n",
    "- The `category` dtype is not a native Python data type but is provided by `Pandas` to optimize memory usage and performance for data with a small number of distinct values\n",
    "- The `sparse` dtype is used for data that is mostly missing to save memory by only storing the non-missing values\n",
    "- The `period` dtype is specific to `Pandas` and is used for handling period data, which is not directly analogous to a native Python type\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and Assigning Data Types\n",
    "\n",
    "When you import your raw data, `Pandas` will attempt to automatically assign a data type to each column, but it doesn't always make the best choice.\n",
    "\n",
    "Let's import some example data to a `DataFrame` and take a look at how to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Create a simple dataframe of names and ages\n",
    "data = {'Name': ['Alice', 'Bashar', 'Carlos', 'Diana', \"Ephraim\", \"Frank\", \"Gina\"],\n",
    "        'Age': [21, 22, 'n/a', 24, 25, 'missing', 27]}\n",
    "age_df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Data Type\n",
    "\n",
    "The data types of your columns can be accessed via the `.dtypes` attribute, or by calling the `.info()` method. \n",
    "\n",
    "- The `.dtypes` attribute only returns the data type of each column\n",
    "- The `.info()` method returns both the data type and some additional information: the number of rows and the memory usage of the dataframe, as well as the number of non-null values in each column. We will deal with handling `NULL` values in another lesson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name    object\n",
       "Age     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    7 non-null      object\n",
      " 1   Age     7 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 244.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "age_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output of `info()`, both columns have defaulted to the `object` datatype. In this case, this is not quite what we want. The `Name` column should be of `string` type, as this uses less memory than `object`, and the `Age` column should be of a numeric type so that we can do numeric calculations on it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The `.astype()` method can be used to manually assign a datatype to a column. We can easily change the `Name` column to the `string` type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    7 non-null      string\n",
      " 1   Age     7 non-null      object\n",
      "dtypes: object(1), string(1)\n",
      "memory usage: 244.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "age_df.Name = age_df.Name.astype('string')\n",
    "age_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we try to cast the `Age` column as `int64` though, the method throws a `ValueError`, because it encountered some values (`missing` and `n/a`) that it could not cast as an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'n/a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/timhowe/Documents/CODE/000_content/Content-Projects/Content/units/Data-Handling/2. Data Manipulation with Pandas/2. Pandas Data Types/Notebook.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/timhowe/Documents/CODE/000_content/Content-Projects/Content/units/Data-Handling/2.%20Data%20Manipulation%20with%20Pandas/2.%20Pandas%20Data%20Types/Notebook.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m age_df\u001b[39m.\u001b[39mAge \u001b[39m=\u001b[39m age_df\u001b[39m.\u001b[39mAge\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint64\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[1;32m   6236\u001b[0m     ]\n\u001b[1;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mastype(dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/internals/managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy, errors\u001b[39m=\u001b[39merrors)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/internals/blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[0;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39mcopy, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    300\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    301\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    227\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    232\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:170\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mor\u001b[39;00m is_object_dtype(arr\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m    169\u001b[0m     \u001b[39m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'n/a'"
     ]
    }
   ],
   "source": [
    "age_df.Age = age_df.Age.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `pd.to_numeric()` Function\n",
    "\n",
    "By default, the `astype()` method throws an error when it encounters a non-convertible value, as this prevents accidental data loss. We can override this behaviour by setting the `errors` flag to `ignore` rather than `raise`, but this would still not convert the datatype to a numeric value. The non-numeric values would still keep the column as an `object` datatype.\n",
    "\n",
    "In this scenario, we are happy to lose the information in the non-numeric values, for the sake of being able to treat the column as integers. To do this, we can use a separate function, `pd.to_numeric()`, which we can use with the `errors` parameter set to `coerce` to force the conversion:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Name    7 non-null      object \n",
      " 1   Age     5 non-null      float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 244.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "age_df.Age = pd.to_numeric(age_df.Age, errors='coerce')\n",
    "age_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values which could not be converted to numeric have now been converted to `NaN` (Not a Number) values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bashar</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carlos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ephraim</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name   Age\n",
       "0    Alice  21.0\n",
       "1   Bashar  22.0\n",
       "2   Carlos   NaN\n",
       "3    Diana  24.0\n",
       "4  Ephraim  25.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `datetime64` Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In `Pandas`, the `datetime64` data type provides a memory-efficient structure for working with date and time data, allowing for operations like time-based indexing, slicing, and resampling to be performed. This data type is necessary for effective time-series data analysis, as it allows complex temporal computations and aggregations to be performed with relative ease.\n",
    "\n",
    "Date-time columns can be challenging to assign correctly, because there is a very large range of ways that date and time columns can be formatted, and there is no guarantee that each column will only use one of these formats, so it is important to determine which formats are used in your data before attempting to convert a column to `datetime64`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting a Column to Datetime\n",
    "\n",
    "The `pd.to_datetime` function can be used to cast a column to `datetime64`. In order to ensure that the conversion is accurate, it is necessary to consider the format that the date/time values are in.\n",
    "\n",
    "Run the three code blocks below to perform a simple example conversion, and confirm that the `datetime64`-encoded dates are correct. In this case, the data are initially formatted as strings, and the date format is unambiguous, and so the conversion works without any additional work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 1 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   date_strings  4 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 164.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'date_strings': ['2023-01-01', '2023-02-01', '2023-03-01', '2023-04-01']\n",
    "}\n",
    "date_df = pd.DataFrame(data)\n",
    "\n",
    "date_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 1 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   date_strings  4 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 164.0 bytes\n"
     ]
    }
   ],
   "source": [
    "date_df.date_strings = pd.to_datetime(date_df.date_strings)\n",
    "date_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_strings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_strings\n",
       "0   2023-01-01\n",
       "1   2023-02-01\n",
       "2   2023-03-01\n",
       "3   2023-04-01"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Common Issues: *Epoch* Time\n",
    "\n",
    "Date and time are typically represented in computers using a system known as *epoch time* or *Unix time*, which counts the number of seconds that have elapsed since a predefined point in time, known as the *epoch*. The **epoch** is set at `00:00:00 UTC on Thursday, January 1, 1970` and the count of seconds (or milliseconds in some applications) from this point is used to represent subsequent points in time, allowing for a standardized, system-independent representation of time that can be easily computed and converted into various human-readable formats.\n",
    "\n",
    "This convention is the source of common issue encountered when converting columns to datetime. For an example, let's load in this dataframe of flight times, `flights_df`, and look at the `FLIGHTDATE` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20110511\n",
       "1    20160520\n",
       "2    20040922\n",
       "3    20160527\n",
       "4    19970511\n",
       "Name: FLIGHTDATE, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None) # You can use this setting display all the columns in your dataframe\n",
    "flights_df = pd.read_csv(\"flights_sample.csv\") \n",
    "\n",
    "flights_df['FLIGHTDATE'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`Pandas` has detected the `dtype` of the  `FLIGHTDATE` column as `int64`, whereas it would be more helpful to have it as `datetime64`, so that it can be used in time-series analysis.\n",
    "\n",
    "Run the two code block below, to see what happens when we try using the function on the `FLIGHTDATE` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1970-01-01 00:00:00.020110511\n",
       "1   1970-01-01 00:00:00.020160520\n",
       "2   1970-01-01 00:00:00.020040922\n",
       "3   1970-01-01 00:00:00.020160527\n",
       "4   1970-01-01 00:00:00.019970511\n",
       "Name: FLIGHTDATE, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(flights_df['FLIGHTDATE']).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the first few values of the column are in January, 1970. This should arouse suspicion, given what we know about **Epoch time**. We can see from the head of the original column that the first 5 values should be between 1997 and 2016, not in 1970. The function has interpreted the integer values in `FLIGHTDATE` as a number of seconds after the **Epoch**, when actually it should be a date in the format`YYYmmdd`.\n",
    "\n",
    "To work around this, we can specify a format as an argument to the `to_datetime` function, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2011-05-11\n",
       "1        2016-05-20\n",
       "2        2004-09-22\n",
       "3        2016-05-27\n",
       "4        1997-05-11\n",
       "            ...    \n",
       "119175   2016-05-18\n",
       "119176   2014-09-25\n",
       "119177   2016-01-13\n",
       "119178   1997-01-04\n",
       "119179   2012-09-07\n",
       "Name: FLIGHTDATE, Length: 119180, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Assign date_format\n",
    "date_format = \"%Y%m%d\"\n",
    "pd.to_datetime(flights_df[\"FLIGHTDATE\"], format=date_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Issues: Mixed Date Formats\n",
    "\n",
    "Handling multiple date formats in a single column can be a bit tricky, but `pd.to_datetime` is quite flexible and can infer different formats automatically in most cases. Below is a simple example of a column called `mixed_dates`, which has dates in multiple formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe:\n",
      "   mixed_dates\n",
      "0   01/02/2023\n",
      "1   2023-03-01\n",
      "2  04-Apr-2023\n",
      "3     20230505\n",
      "\n",
      "Data types:\n",
      "mixed_dates    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a sample dataframe with multiple date formats\n",
    "data = {\n",
    "    'mixed_dates': ['01/02/2023', '2023-03-01', '04-Apr-2023', '20230505']\n",
    "}\n",
    "mixed_date_df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying the original dataframe\n",
    "print(\"Original Dataframe:\")\n",
    "print(mixed_date_df)\n",
    "print(\"\\nData types:\")\n",
    "print(mixed_date_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modified dataframe:\n",
      "   mixed_dates      dates\n",
      "0   01/02/2023 2023-01-02\n",
      "1   2023-03-01        NaT\n",
      "2  04-Apr-2023        NaT\n",
      "3     20230505        NaT\n",
      "\n",
      "Data types:\n",
      "mixed_dates            object\n",
      "dates          datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Converting the 'mixed_dates' column to datetime\n",
    "# Note: infer_datetime_format=True can help to infer different formats, but might not handle all cases\n",
    "mixed_date_df['dates'] = pd.to_datetime(mixed_date_df['mixed_dates'], infer_datetime_format=True, errors='coerce')\n",
    "\n",
    "# Displaying the modified dataframe\n",
    "print(\"\\nModified dataframe:\")\n",
    "print(mixed_date_df)\n",
    "print(\"\\nData types:\")\n",
    "print(mixed_date_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately in this case, automatic conversion has not been very effective, and we can see multiple values have been returned as `NaT` (Not a Time).\n",
    "\n",
    "A more effective approach is to use the `parse` function from the `dateutil` library, in conjunction with the `.apply` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modified dataframe:\n",
      "\n",
      "   mixed_dates      dates\n",
      "0   01/02/2023 2023-01-02\n",
      "1   2023-03-01 2023-03-01\n",
      "2  04-Apr-2023 2023-04-04\n",
      "3     20230505 2023-05-05\n",
      "\n",
      "Data types:\n",
      "\n",
      "mixed_dates            object\n",
      "dates          datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "mixed_date_df['dates'] = mixed_date_df['mixed_dates'].apply(parse)\n",
    "mixed_date_df['dates'] = pd.to_datetime(mixed_date_df['dates'], infer_datetime_format=True, errors='coerce')\n",
    "print(\"\\nModified dataframe:\\n\")\n",
    "print(mixed_date_df)\n",
    "print(\"\\nData types:\\n\")\n",
    "print(mixed_date_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `timedelta64` Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `timedelta64` data type is used to represent differences in `datetime64` objects. While a `datetime64` object represents a specific point in time, with a defined year, month, day, hour, minute, and so on, a `timedelta64` object represents a duration that is not anchored to a specific start or end point. It tells you how much time is between two points, without specifying what those points are.\n",
    "\n",
    "The distinction between `timedelta64` and `datetime64` data types in `Pandas` (and similarly, `timedelta` and `datetime` in Python's `datetime` module) is crucial due to the inherent differences in representing and utilizing points in time versus durations of time, which are fundamentally different concepts.\n",
    "\n",
    "**Arithmetic Operations:**\n",
    "   - When you perform arithmetic with two `datetime64` objects, the result is a `timedelta64` object because subtracting one point in time from another gives you a duration\n",
    "   - Conversely, when you add or subtract a `timedelta64` from a `datetime64` object, you get another `datetime64` object because you're shifting a point in time by a certain duration\n",
    "\n",
    "By having separate data types, `Pandas` (and Python more broadly) allows for clear, intuitive operations on time data, ensuring that the operations are semantically meaningful and that the results are what users expect when performing arithmetic or comparisons with time-related data. This distinction also helps prevent misinterpretation of the data and ensures that operations are performed with the appropriate level of precision and efficiency for each type of data.\n",
    "\n",
    "For example, the code block below creates a new `timedelta64` column by subtracting a specific timestamp from the `dates` column of the `mixed_dates_df` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modified dataframe:\n",
      "   mixed_dates      dates date_difference\n",
      "0   01/02/2023 2023-01-02          1 days\n",
      "1   2023-03-01 2023-03-01         59 days\n",
      "2  04-Apr-2023 2023-04-04         93 days\n",
      "3     20230505 2023-05-05        124 days\n"
     ]
    }
   ],
   "source": [
    "# Subtracting a single date from the 'dates' column\n",
    "single_date = pd.Timestamp('2023-01-01')  # Creating a Timestamp object\n",
    "mixed_date_df['date_difference'] = mixed_date_df['dates'] - single_date  # Subtracting the single date\n",
    "\n",
    "# Displaying the modified dataframe\n",
    "print(\"\\nModified dataframe:\")\n",
    "print(mixed_date_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content_repo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSK Connect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Amazon MSK Connect used for in Apache Kafka?\n",
    "\n",
    "- To provide a streaming data platform that enables real-time data processing and analytics\n",
    "- To facilitate the transfer of data between different AWS services, such as S3 and Redshift\n",
    "- To simplify the process of creating, deploying, and managing connectors that move data between Kafka and other systems ***\n",
    "- To provide a messaging system that guarantees delivery of messages in the correct order"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the main difference between source and sink connectors in Amazon MSK Connect?\n",
    "\n",
    "- Source connectors are used to move data from Kafka to external systems, while sink connectors are used to move data from external systems to Kafka\n",
    "- Source connectors are used to move data between different Kafka clusters, while sink connectors are used to move data between Kafka and external systems\n",
    "- Sink connectors are used to move data from Kafka to external systems, while source connectors are used to move data from external systems to Kafka ***\n",
    "- There is no difference between source and sink connectors in Amazon MSK Connect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the process for creating a sink connector in Amazon MSK Connect that will send data from a Kafka topic in an MSK cluster to an S3 bucket?\n",
    "\n",
    "- Configure the connector using the AWS Management Console, specifying the S3 bucket and the Kafka topic as the source of data. Then, deploy the connector to the MSK cluster using the provided instructions\n",
    "\n",
    "- Write a custom connector using the Kafka Connect API, specifying the S3 bucket and the Kafka topic as the source of data. Then, deploy the connector to the MSK cluster using the provided instructions\n",
    "\n",
    "- Create a connector based on a pre-buit plugin that integrates Kafka and S3, specifying the S3 bucket and the Kafka topic as the source of data. Then, deploy the connector to the MSK cluster using the provided instructions ***\n",
    "\n",
    "- There is no way to send data from a Kafka topic in an MSK cluster to an S3 bucket using Amazon MSK Connect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the difference between plugins and connectors in Amazon MSK Connect?\n",
    "\n",
    "- Plugins are used to extend the functionality of connectors, while connectors are used to connect to different data sources and sinks ***\n",
    "- Plugins and connectors are two terms used interchangeably in Amazon MSK Connect to refer to the same thing\n",
    "- Plugins are used to configure the behavior of Kafka Connect, while connectors are used to connect to different data sources and sinks\n",
    "- There is no difference between plugins and connectors in Amazon MSK Connect"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

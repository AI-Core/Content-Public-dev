- id: eeb9b847-215d-41dd-8e42-dbc7dc07350f
  name: Using Selenium using a standalone container
  description: |+
    1. Launch an Ubuntu 20.04 EC2 instance
    2. SSH to the EC2 instance
    3. Install Docker (Google "Install Docker Engine")
    4. You will have to change your selenium webdriver. Instead of using chromedriver, geckodriver, or any webdriver you were using so far, you will use the `Remote` webdriver. So, this will look like this:"
      - `driver = webdriver.Remote('http://127.0.0.1:4444/wd/hub', DesiredCapabilities.CHROME)`
      - The primary difference is that a Remote webdriver needs to be configured so that it can run your tests on a separate machine."
    5. So now you have two options:
    6. Make these changes locally and push them to a new repository, or a new branch in your current repository
    7. Make the changes in the EC2 instance if you are familiar with Vim or Nano text editors
      - Run the image from this webpage https://hub.docker.com/r/selenium/standalone-chrome
      - Remember that: docker run -d -p 4444:4444 --shm-size=2g selenium/standalone-chrome:4.0.0-rc-2-prerelease-20210923 is going to expose the container to port 4444, which is the same one you use when defining your driver. So if you make any change, that change has to be reflected in both places.
    8. Install any requirement needed by your scraper, most likely you will need selenium.
    9. Run you python file. You don't have to containerize the scraper yet

- id: e8b517b3-e91f-4a28-9f3b-9ed3c55c2d0e
  name: Using Selenium within a docker container
  description: |+
    1. Download the following markdown file for chrome or firefox:
      - https://aicore-files.s3.amazonaws.com/Foundations/DevOps/docker_selenium.md
      - https://aicore-files.s3.amazonaws.com/Cloud-DevOps/docker_firefox.md
    2. Follow the instructions to containerise a webscraper with Selenium inside
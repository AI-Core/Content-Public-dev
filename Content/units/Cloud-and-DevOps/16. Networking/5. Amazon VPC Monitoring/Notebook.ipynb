{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VPC Monitoring\n",
    ">At a high level, *network monitoring* or *logging* is the process of documenting every event that takes place on a device. From a networking perspective, this allows you to ensure security by observing the flow of traffic in and out of your network at a fine granularity, in addition to optimising your resources. It is a crucial part of developing a robust network infrastructure.\n",
    "\n",
    "When discussing network monitoring or logging it is common to use some of the following metrics:\n",
    "\n",
    "- **Throughput:** The rate of traffic, in bytes per second, passing through a device during a specific time period\n",
    "\n",
    "- **Uptime**: Also known as *availability*, this is the amount of time that a network device successfully sends and receives data\n",
    "- **Bandwidth:** The amount of data, in bytes, that is currently being sent or received by a device. Engineers track both the volume of traffic being sent, and the percentage of total bandwidth that is being utilised.\n",
    "- **CPU utilisation:** Also sometimes called *compute*. This metric is how much a device has used its computational capacity to process input, store data, and create output.\n",
    "- **Interface errors/discards:** These are errors on the receiving device that cause a network interface to drop a data packet. Interface errors and discards can stem from configuration errors or bandwidth issues, for example.\n",
    "- **IP metrics:** IP metrics such as *latency* can measure the speed and efficiency of connections between devices.\n",
    "\n",
    "The remainder of this section deals with some of the more common VPC monitoring services for AWS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS CloudWatch\n",
    ">*AWS CloudWatch* is a service which monitors any of your AWS resources or applications hosted on AWS resources, in real time. It is a metrics repository which you can use to collect, organise and visualise metrics in graph and dashboard form. You can also create alarms to watch metrics and send automatic notifications or automatically modify resources when a threshold is breached. For example, you could monitor CPU usage of an EC2 instance then use that data to decide whether to launch a new instance to handle increased load.\n",
    "\n",
    "These are the core concepts fundamental to understanding AWS CloudWatch:\n",
    "\n",
    "- **Namespaces:** A namespace is a container for metrics. There is a different, isolated namespace for each AWS service that produces CloudWatch-supported metrics, refer to [this](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html) documentation for the full list. Namespaces are denoted as `AWS/<service>`, so metrics for an EC2 instance would be from the `AWS/EC2` namespace\n",
    "\n",
    "- **Metrics:** The most fundamental concept of CloudWatch, a metric is a stream of data points produced by a single variable over time. The SSD storage being used for an RDS instance usage, for example.\n",
    "- **Dimensions**: Key/value pairs that help to categorise metrics. You can assign multiple dimensions to each metric, which then allows you to split the same metric into subcategories, which is useful for aggregating statistics with them later. \n",
    "    \n",
    "    For example, you have a prod and a dev EC2 instance in two different regions, but you want to calculate their CPU usage separately. To achieve this you would assign them each a dimension for their server type, and for their region, which would ultimately look like this:\n",
    "\n",
    "    ```\n",
    "    Dimensions: Server=Prod, Region=eu-west-1, Unit: CPU Usage, Timestamp: 2016-10-31T12:30:00Z, Value: 10%\n",
    "    Dimensions: Server=Beta, Region=eu-west-1, Unit: CPU Usage, Timestamp: 2016-10-31T12:31:00Z, Value: 11%\n",
    "    Dimensions: Server=Prod, Region=uk-south,  Unit: CPU Usage, Timestamp: 2016-10-31T12:32:00Z, Value: 95%\n",
    "    Dimensions: Server=Beta, Region=uk-south,  Unit: CPU Usage, Timestamp: 2016-10-31T12:33:00Z, Value: 97%\n",
    "    ```\n",
    "\n",
    "- **Resolution:** The frequency at which the metric data points are gathered. This is either *Standard* or *High* resolution. Standard resolution is data gathered at a one minute time interval, high resolution is at one second.\n",
    "- **Statistics:** Aggregations of metrics over specific periods of time\n",
    "- **Alarms:** An alarm watches a single metric and can automatically initiate actions depending on the value of the metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CloudWatch Alarm Example\n",
    "To better understand CloudWatch Alarms, examine the image below. It shows the details pane of an alarm which will send a notification when the maximum CPU utilisation of an EC2 instance over a period of 5 minutes reaches a threshold of 70%. \n",
    "\n",
    "<p align=\"center\"> <img src=\"images/cloudwatch-alarm.png\" height=\"605\" width=\"1262\"/> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## AWS CloudTrail\n",
    ">*AWS CloudTrail* is an event tracking system for an AWS account. Actions taken by a user, role, or an AWS service are recorded as events in CloudTrail. Just like CloudWatch you can organise and visualise the events in a dashboard.\n",
    "\n",
    "CloudTrail provides three ways to record events:\n",
    "\n",
    "- **Event history:** A searchable record of the past 90 days of events in an AWS region. This is a free feature, and you automatically have access to CloudTrail Event History by default when you create an AWS account.\n",
    "\n",
    "- **CloudTrail Lake:** A managed data lake for capturing, storing and analysing user activity. You can keep the data for up to 10 years or up to 7 years, depending on which pricing plan you choose. You can also import existing CloudTrail logs from S3 buckets into CloudTrail Lake to use the dashboarding features.\n",
    "\n",
    "- **Trails:** Captures and records events, storing them in an S3 bucket, with optional delivery to CloudWatch logs or other external security and monitoring solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VPC Flow Logs\n",
    ">*VPC Flow Logs* are a component of the VPC ecosystem that allow you to capture very detailed information about traffic going to and from a VPC, subnets, and at instance level. \n",
    "\n",
    "The logs can be sent to S3, CloudWatch logs or other data streaming and monitoring services. Flow logs collect data from outside the path of the traffic, so they do not affect network throughput or latency.\n",
    "\n",
    "Use cases of flow logs:\n",
    "\n",
    "- Troubleshooting connectivity issues\n",
    "- Configuring overly restrictive or permissive Security Groups or NACLs\n",
    "- Detecting malicious intrusions \n",
    "\n",
    "### Flow Log Records\n",
    "The image below is an example of what flow log records look like. \n",
    "\n",
    "In the first record, HTTP traffic (desination port 80, TCP protocol) containing 3 packets of data of size 140 bytes, from IP address `83.234.179.125` has been rejected access to private IP address `172.31.22.145`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"> <img src=\"images/flow-log-records.png\" height=\"384\" width=\"934\"/> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "- Monitoring is a very important part of a complete and robust VPC infrastructure. Some metrics which can be discussed are: throughput, uptime, bandwidth, CPU utilisation, interface errors and IP metrics.\n",
    "- AWS Cloudwatch is a monitoring and analysis service for AWS resources, which you can use to notify you of instance state changes and automatically make changes to the instance itself. It's core components are: namespaces, metrics, dimensions, resolution, statstics and alarms. \n",
    "- Flow logs are a fundamental component of Amazon VPCs which collect thoroughly detailed traffic data, and can deliver it to log storage and analysis services"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

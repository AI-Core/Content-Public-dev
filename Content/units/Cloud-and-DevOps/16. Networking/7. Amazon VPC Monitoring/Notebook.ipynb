{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon VPC Monitoring\n",
    ">At a high level, *monitoring* and *logging* are key practices in managing and maintaining the health and performance of IT systems. They involve tracking, storing and analysing a selection of metrics to observe system or resource health, performance and security.\n",
    "\n",
    "There are many reasons why monitoring is an important part of a robust networking infrastructure. Here are a few:\n",
    "\n",
    "- **Capacity Planning:** Monitor network usage and trends to make informed decisions on resource upgrades and scalability to accommodate future growth\n",
    "\n",
    "- **Security Threat Detection:** Detect unusual or suspicious activities that could indicate security threats, allowing for timely interventions\n",
    "\n",
    "- **Availability Assurance:** Ensure all network components are operational, minimising downtime and improving reliability\n",
    "\n",
    "- **Fault Detection and Response:** Quickly identify and address network failures to restore services and reduce impact on users\n",
    "\n",
    "\n",
    "### Network Monitoring Metrics\n",
    "When discussing network monitoring or logging it is common to use some of the following metrics:\n",
    "\n",
    "- **Throughput:** The rate of traffic, in bytes per second, passing through a device during a specific time period\n",
    "\n",
    "- **Uptime**: Also known as *availability*, this is the amount of time that a network device successfully sends and receives data\n",
    "- **Bandwidth:** The amount of data, in bytes, that is currently being sent or received by a device. Engineers track both the volume of traffic being sent, and the percentage of total bandwidth that is being utilised.\n",
    "- **CPU utilisation:** Also sometimes called *compute*. This metric is how much a device has used its computational capacity to process input, store data, and create output.\n",
    "- **Interface errors/discards:** These are errors on the receiving device that cause a network interface to drop a data packet. Interface errors and discards can stem from configuration errors or bandwidth issues, for example.\n",
    "- **IP metrics:** IP metrics such as *latency* can measure the speed and efficiency of connections between devices.\n",
    "\n",
    "The remainder of this section deals with some of the more common VPC monitoring services for AWS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS CloudWatch\n",
    ">*AWS CloudWatch* is a service which monitors any of your AWS resources or applications hosted on AWS resources, in real time. It is a metrics repository which you can use to collect, organise and visualise metrics in graph and dashboard form. You can also create alarms to watch metrics and send automatic notifications or automatically modify resources when a threshold is breached. For example, you could monitor CPU usage of an EC2 instance then use that data to decide whether to launch a new instance to handle increased load.\n",
    "\n",
    "These are the core concepts fundamental to understanding AWS CloudWatch:\n",
    "\n",
    "- **Metrics:** The most fundamental concept of CloudWatch, a metric is a stream of data points produced by a single variable over time. The amount of SSD storage being used over time for an RDS instance usage, for example.\n",
    "\n",
    "- **Namespaces:** A namespace functions as a distinct container where all the monitoring data (metrics) from a specific AWS service are stored and managed. Each AWS service that supports CloudWatch sends its data to a unique namespace, ensuring that the metrics from different services are kept separate and organised. Namespaces are denoted as `AWS/<service>`, so metrics for an EC2 instance would be from the `AWS/EC2` namespace. Refer to [this](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html) documentation for the full list. \n",
    "\n",
    "- **Dimensions**: Key/value pairs that help to categorise metrics. You can assign multiple dimensions to each metric, which then allows you to split the same metric into subcategories, which is useful for aggregating statistics with them later. \n",
    "    \n",
    "    For example, a public website is being hosted by an EC2 instance, alongside a replica EC2 instance for website development purposes. In addition, this set up is replicated across another AWS region. In order to calculate the CPU usage of the instances separately, a dimension could be assigned each for their server type (production or development), and for their region, which would ultimately look like this:\n",
    "\n",
    "    ```\n",
    "    Dimensions: Server=Prod, Region=eu-west-1, Unit: CPU Usage, Timestamp: 2016-10-31T12:30:00Z, Value: 10%\n",
    "    Dimensions: Server=Dev, Region=eu-west-1, Unit: CPU Usage, Timestamp: 2016-10-31T12:31:00Z, Value: 11%\n",
    "    Dimensions: Server=Prod, Region=uk-south,  Unit: CPU Usage, Timestamp: 2016-10-31T12:32:00Z, Value: 95%\n",
    "    Dimensions: Server=Dev, Region=uk-south,  Unit: CPU Usage, Timestamp: 2016-10-31T12:33:00Z, Value: 97%\n",
    "    ```\n",
    "\n",
    "- **Resolution:** The frequency at which the metric data points are gathered. This is either *Standard* or *High* resolution. Standard resolution is data gathered at a one minute time interval, high resolution is at one second.\n",
    "\n",
    "- **Statistics:** Aggregations of metrics over specific periods of time\n",
    "\n",
    "- **Alarms:** An alarm watches a single metric and can automatically initiate actions depending on the value of the metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CloudWatch Alarm Example\n",
    "To better understand CloudWatch Alarms, examine the image below. It shows the details pane of an alarm which will trigger and send a notification when the average CPU utilisation of an EC2 instance over a period of 5 minutes reaches a threshold of 70%. \n",
    "\n",
    "<p align=\"center\"> <img src=\"images/cloudwatch-alarm.png\" height=\"529\" width=\"1598\"/> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For complete illustration purposes, this is a graph of CPU utilisation of the EC2 instance in the above example. \n",
    "\n",
    "<p align=\"center\"> <img src=\"images/CPU-utilisation-graph.png\" height=\"507\" width=\"820\"/> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## AWS CloudTrail\n",
    ">*AWS CloudTrail* is an event tracking system for an AWS account. Actions taken by a user, role, or an AWS service are recorded as events in CloudTrail.\n",
    "\n",
    "CloudTrail provides three ways to record events:\n",
    "\n",
    "- **Event history:** A searchable record of the past 90 days of events in an AWS region. This is a free feature, and you automatically have access to CloudTrail Event History by default when you create an AWS account.\n",
    "\n",
    "- **CloudTrail Lake:** A managed data lake for capturing, storing and analysing user activity. You can keep the data for up to 10 years or up to 7 years, depending on which pricing plan you choose. You can also import existing CloudTrail logs from S3 buckets into CloudTrail Lake to use the dashboarding features.\n",
    "\n",
    "- **Trails:** Captures and records events, storing them in an S3 bucket, with optional delivery to CloudWatch logs or other external security and monitoring solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VPC Flow Logs\n",
    ">*VPC Flow Logs* are a component of the VPC ecosystem that allow you to capture very detailed information about traffic going to and from a VPC, subnets, and at instance level. \n",
    "\n",
    "The logs can be sent to S3, CloudWatch logs or other data streaming and monitoring services. Flow logs collect data from outside the path of the traffic, so they do not affect network throughput or latency.\n",
    "\n",
    "Use cases of flow logs:\n",
    "\n",
    "- Troubleshooting connectivity issues\n",
    "- Configuring overly restrictive or permissive Security Groups or NACLs\n",
    "- Detecting malicious intrusions \n",
    "\n",
    "### Flow Log Records\n",
    "The image below is an example of what flow log records look like. \n",
    "\n",
    "In the first record, HTTP traffic (desination port 80, TCP protocol) containing 3 packets of data of size 140 bytes, from IP address `83.234.179.125` has been rejected access to private IP address `172.31.22.145`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"> <img src=\"images/flow-log-records.png\" height=\"384\" width=\"934\"/> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "- Monitoring is a very important part of a complete and robust VPC infrastructure. Some metrics which can be discussed are: throughput, uptime, bandwidth, CPU utilisation, interface errors and IP metrics.\n",
    "- AWS Cloudwatch is a monitoring and analysis service for AWS resources, which you can use to notify you of instance state changes and automatically make changes to the instance itself. It's core components are: namespaces, metrics, dimensions, resolution, statstics and alarms. \n",
    "- Flow logs are a fundamental component of Amazon VPCs which collect thoroughly detailed traffic data, and can deliver it to log storage and analysis services"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# Prometheus

## Setup

open .code.ipynb
Have a Prometheus server running with node exporter
Leave Prometheus to run for a while to collect enough metrics to show examples.
Have `example.rules.yml` ready in .video folder

## Querying

- Prometheus has a lot of querying capabilities ( including it's own query language PromQL) which we will learn to use today.
- Have an instance of a Prometheus server running with a node exporter or windows exporter to being the lesson.

__`[SHOW ON PROMETHEUS]`__ Open http://localhost:9090
- Open Prometheus by going to your localhost on port 9090 to have the expression/query prompt open.

## Data Types

- Prometheus has only four data types
  - float64 any scalar is a float
  - string which is currently unused by Prometheus
  - instant vectors and range vectors

### Instant vector selectors

- Instant vectors are created via SELECTION based on some matching patterns such as lables, metric names etc.
- The easiest form is just a simple metric name statement returning a vector of values

__`[RUN ON PROMETHEUS]`__ 
- You can do this by typing the metric name into the Prometheus expressions input box
- running `node_cpu_seconds_total` and then selecting the graph we can get a display of the time the cpu took running in different modes. 
- We can further filter this metric by specific labels for example
- running `node_cpu_seconds_total{cpu=~"0|1", instance!="localhost:8081", mode="user"}` we can get the output of the cpus 0 and 1 run by the user.

### Matching

- Prometheus supports different comparison operators and regex matching (via Google RE2 syntax). 
__`[SHOW IN BROWSER]`__ https://github.com/google/re2/wiki/Syntax
- Here you will find all syntax for matching strings using Google RE2. 
- For instance `.` will specify any character.
- It also has inbuilt support for Comparison operators:

__`[SHOW ON SLIDES]`__ Different comparison operators for matching
  - These function much in the same way you are used to in Python.

### name

- Similar to Python's `__name__` Prometheus also provides this `label` internally. It allows the matching of expressions for example:
- A quick way to match strings is using the ".*" expression, the `.` signifies matching any character and the ?* signifies matching any number of characters afterwards.

__`[SHOW IN PROMETHEUS]`__
- Running `{__name__=~"node.*_seconds"}` we get all the node expressions ending in seconds.
- It is important to keep in mind that your Regex expressions has to match something, the expression has to be a valid expression.
- For example we can use `{job=~"wmi.*"}` to return all metrics starting with `wmi` windows exporter metrics.
- Using `{job=~".+"}` we can get all jobs where the string isn't empty. 

### Range vector selectors

- Range vectors are created by slicing timeseries based on time duration. 
- Previously we used curly brackets for instant selectors we will now use square brackets for slicing timeseries based on time duration.

__`[SHOW IN PROMETHEUS]`__  Running commands to get range selectors
- Running `node_cpu_seconds_total{cpu=~"0|1", mode="idle"}[20s]` we can see that we return the amount of cpu seconds run for cpus 1 and 0 in the idle state.
- Even though we have selected the required range selector we can't graph it currently. We need to to change them to instant vectors because they have multiple values for a single timestamp. 
- We now have a multidimensional aggregated data.
  - we get 4 values for each timeseries in the `20s` range since data is scrapped every 5 seconds.
- Given that we can perform some kind of operation on the grouped data to summarise it.
- Here we can use the `rate` operation to get the rate of cpu idle time for cpus 1 and 0 every 20 seconds, which we can now graph. 

__`[SHOW ON SLIDES]`__ Different types of time units available for plotting and examples selecting the time range.
  - Note that you can mix and match the time units but they must be ordered from largest to the smallest unit. 

__`[SHOW ON SLIDES]`__ Show on next slides examples of selecting different time series ranges
  - Here are some examples of time series ranges.

### Offsets

- Offsets allow us to jump to specified point in time.
- for example `rate(htt_requests_total[5m] offset 1w)` will return the 5 minute rate of `http_requests_total` we had a week ago. 
- The command won't run here as there isn't enough data currently to offset but will work with more data.

## Operators 

__`[SHOW ON SLIDES]`__ Table of operators 
- Prometheus's language PromQL provides a standard set of operators logical, arithmetical and comparision for use with your queries.
- These follow standard broadcasting rules between scalars and vectors we already know from `numpy` or `pytorch` except matching between two instant vectors.

### Vector matching

- Vector matching defines one instant vector can be matched to another one.

### One-to-one

- One to one finds a unique pair of entries from each side of the operation.
- The rules are:
  - exact same set of labels
  - and the value types have to match

__`[SHOW IN VS CODE]`__ Syntax of how vector matching is written.
- ignoring allows us to ignore certain lables 
- and on allows us to specify labels

__`[SHOW IN VS CODE]`__ Show examples of one to one vector matching time series.
  - Suppose we have these two groups of timeseries:
  - For specific `instant selectors` we might have this set of metrics, note that the data value for that `instant selector` is commented on the right.
  - Using these metrics let's see what the ratio of failed requests with `code=500` which is an internal server error rate would be. 
  
__`[SHOW ON SLIDES]`__ Vector matching calculation
- Using this calculation we would match every metric were `method=get` with `code=500` and divide it with all other metrics where `method=get` since we're ignoring the `code` values in the denominator.
- Similarly where `method="post"` 
- So we would return two instant vectors.

### Many-to-one & one-to-many

- Each vector element on the "one"-side can match with multiple elements on the "many" side.
- This is possible in Prometheus but should only be used we absolutely necessary.

### Aggregation operations

- Prometheus also provides basic operation for data aggregation.

__`[SHOW ON SLIDES]`__ full list of data aggregation operations


__`[SHOW ON PROMETHEUS]`__ Example of running the min command
  - The simplest form of expression is the name of the aggregation then the vector expression. 
  - Let's try running the min command on `min(node_cpu_scaling_frequency_hertz)`, in this case the minimum value for each timestep will be taken across all of the labels.

__`[SHOW ON SLIDES]`__
  - To specify labels the labels to run the operation across there its two modifiers.
  - by - which specifies by which labels the min is taken across.
  - without - which specifies which label the min is taken.
  - For example getting the minimum taken for each cpu core separately we run `min by (cpu) (node_cpu_scaling_frequency_hertz)`

### Functions

- Prometheus also provides a set of function that you can use, currently the set is a little limited and you cannot add your own.
  - Normal rules apply with functions(e.g some have default arguments)
  - Some operate on range vectors, while others on instant vectors

- Some of the groups of functions are
  - `date` related functions (minute,year,timestamp etc)
  - `math` related (ln,exp,driv,round)
  - `timeseries` related (`delta` )

__`[SHOW IN PROMETHEUS]`__ Running delta function
  - For example we could run `delta(node_hwmon_temp_celsius[10m])` which will monitor the hardware temperature difference of 10m intervals.
  - or `exp(node_hwmon_temp_celsius)` which will give the exponential value of temperatures.
  - The last set of functions provided is the over time functions
  - We can run `stddev_over_time(node_context_switches_total[10s])` to get the standard deviations over a range of vectors of the number or context switches performed by the operating system.

### Recording Rules

- And finally we can record rules in Prometheus which allow us to precomputed frequently used/expensive and queries and save results as a new timeseries.
- You should always try and create new rules instead of running ad-hoc commands since:
  - They are fast since they work on less data on a regular basis.
  - They are more readable for others
  - They're easy to reuse
  - and easy to add to version control systems like `git`

- Rules are usually written in a separate YAML file 
- 
__`[SHOW .example.rules.yml]`__
- The general layout is to name the group the interval to scrape for and then define the expressions you would like to scrape. 
  
### Groups

- Rules within a group are run sequentially as defined in a regular interval
- Those should be grouped by:
  - semantic meaning
  - evaluation interval

### Naming

There a few guidelines you should stick to:

__`[SHOW IN VS CODE]`__ Examples of defining rules
- Recording rules should be of the general form `level:metric:operations`
  - `level` labels of the rule output/aggregation level
  - `metric` name of metric e.g `http_requests`
  - `operations` - key operations creating the result
- Here are some examples of how to define some rules in your rules YAML file.

## Including rules in prometheus.yml

- To include the rules in the `prometheus.yml` we have to define where Prometheus will look for the rules files.

__`[SHOW IN VS CODE]`__ Example of how to define the rules files in a YAML.
- Using this format we have defined the rules files for Docker and the node exporter.
- You can see the general syntax by convention is name for the set of rules then rules and the yaml extension. Then define the path to the files under the `rule_files` parameter.
- You can also effect the rules by changing the global parameter which will effect their default scrape interval. 
- Setting up the files in this way will allow them to be available in Prometheus under the record name you have specified!

## Outro

So we have now learned how to use Prometheus's powerful querying language PromQL to create different queries to get the metric results we want. You have learned how you can use operators, functions and ranges to create custom metrics specific to your needs. We also now know to create rules for any expressions we will use on a constant basis. I hope this video gave some insight on how to perform powerful queries on Prometheus metrics and as always for more information refer to the documentation, thanks everyone.
  


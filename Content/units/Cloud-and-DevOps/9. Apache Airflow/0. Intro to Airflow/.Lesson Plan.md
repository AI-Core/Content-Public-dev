# 4. Apache Airflow

- What is a workflow?
    - Set of steps to accomplish a data engineering task:
        - Scraping Data
        - Filtering Data
        - Cleaning Data
        - Imputing Data
        - Run ML Pipeline
        - Make a Report

- Airflow helps us program workflows:
    - Create
    - Schedule
    - Monitor
- Written in Python, using DAGs

- Alternatives to workflows
    - Luigi
    - SSIS
    - Bash

- What is a DAG: Directed Acyclic Graph (They should have already seen it in the SoftEng unit)
    - Each node represent a task of the workflow
    - They are connected according to their dependencies
    - They are acyclic, so no loops
    
    - Airflow gives metadata to the DAG, such as name, start date, owner... And they are defined in the default_args dictionary

- Run through the examples, everything is quite well defined
- Make sure they follow all steps and you show the UI
- Make sure they understand the DAG structure as well as how the tasks are connected

-[BREAK] Take a break after explaining the UI

- Run through the examples
- Make sure everyone has Airflow correctly installed
- Run the BashOperator example
- Go to the exercise

-[BREAK] Take a break after everyone completed the exercise

- 
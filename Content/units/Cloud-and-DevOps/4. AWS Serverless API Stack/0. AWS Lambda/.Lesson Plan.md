# AWS Lambda

## What is AWS Lambda?
- AWS Lambda is a service that allows you to run custom code called a lambda function in the cloud without managing your own servers
- in the background, when your lambda function triggered, AWS turns on a computer runs the code and then turns it off
- we call this serverless computing
- it's good because 
    - you don't have to pay for servers when you're not using them
    - you dont have to manage server uptime, security or scaling
- lambda functions can be triggered in many ways:
    - when an item is uploaded to a particular S3 bucket
    - periodically using a cron job, or more specifically by an AWS Cloudwatch Rule
    - as the backend integration to an API
    - they can be triggered programatically through python
    - that means that they can even be triggered by themselves!
    - and many more

## Our first lambda function
- go to lambda console
    - https://eu-west-2.console.aws.amazon.com/lambda/home?region=eu-west-2#/functions?f0=true&n0=false&op=and&v0=demo
- we'll look at the default lambda function
- we define the handler as a file, function combination
    - handler.lambda_handler
- this is the function which gets executed when the lambda function is triggered
- two arguments are always passed to the function
    - the event is passed in as the first argument
    - the context is passed in as the second argument
    - https://stackoverflow.com/questions/53936773/what-are-event-and-context-in-function-call-in-aws-lambda
- we can see the default timeout and memory consumption here
- lambda pricing is based on the product of the time that your function runs for, and the memory it consumes
- we call all of the code inside the lambda function a deployment package

## Demo 1: Periodically making an API request and saving the result
- our aim is to get the top scoring posts on stack overflow, and save it to our data lake
- this will incorporate a few new things
    - we'll need to bundle the requests library as a 3rd party dependency with our deployment package
    - we'll need to interact with other AWS services
- write the initial code
    - inside the handler:
        - import requests
- implement best practices
    - https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html
    - a few best practices to identify here. Make the following updates to the code
        - separate the logic of the code from the handler
            - make code more unit-testable
        - define the AWS clients outside of the handler
- define a simple test and run the test
- show that with the default
- try to run it
    - no module named requests
- get access to the requests library
    - few libraries are installed by default in the python environment that the lambda runs
    - 3rd party dependencies should be packaged as a lambda layer, which is just the source code for the dependencies you require, deployed as a zip package
    - go to the lambda layers console
    - create a layer
    - now make the layer's deployment package zip file
        - they need to have a specific structure
            - the folder which gets zipped up must contain the python folder
            - this is just the format that the lambda function expects it in
            - this will vary for different runtimes
        - the python folder should contain the source code and nothing else
            - go inside the python folder and run
                - `pip install -t . requests`
                - the t flag specifies the target directory
        - then go to the parent of the python directory and zip up
            - `zip -r requests_layer.zip .`
            - i.e. if you unzipped the deployment package, it would be a folder containing the python folder
    - now we've created the layer we can add it to the lambda function, from within the functions console
        - we do so by specifying the lambda layer's ARN (amazon resource name)
    - things you should know about layers
        - 30MB deployment package limit
            - yes, that means you cant create a pytorch layer
        - can't reference each other
            - e.g. one layer cant import from another
        - as well as the lambda function code, we might refer to the code in a lambda layer zip a deployment package
    - read more about layers here
        - https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html
- try to run it
    - timeout error
- try to run it
    - s3 upload permissions 
- we need permissions to access other resources
    - go to the configuration tab
    - create a new IAM role
        - give it write S3 runtime permissions
- check the bucket
    - https://s3.console.aws.amazon.com/s3/buckets/aicore-demo-bucket?region=eu-west-2&tab=objects

## Triggering a lambda function from cloudwatch
- We'll look at cloudwatch more later for logging
- for now one thing we'll quickly look at is cloudwatch rules - a way to trigger lambda functions periodically
- go to cloudwatch console and open the rules
- create rule -> schedule 
    - set every minute
- add target
    - you'll need to be in the same region as your lambda function
    - add the lambda function
- wait a minute and check the S3 bucket

## Key takeaways
- serverless computing is where you can run code without managing servers
- AWS Lambda allows you to do serverless computing
- we can create a lambda function handler and write the code which we want to run
- we can create our own dependencies in the form of lambda layers
- we can assign an IAM execution role to the lambda function to give it permission to access other AWS resources
- cloudwatch rules can be used to trigger lambda functions periodically

## Comprehension questions
- what are some of the common reasons a lambda function might fail?
    - memory
    - timeout
    - permissions
- what might we use a lambda function for?
- 
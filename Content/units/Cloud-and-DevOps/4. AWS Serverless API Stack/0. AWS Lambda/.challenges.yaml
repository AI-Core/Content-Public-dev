- id: 97b9b2b7-682e-4b65-864d-63001ee59e2d
  name: Create your first lambda function
  description: |
    - this should be done individually
    - head over to the AWS Lambda console and click create function
    - give your function a name and select python 3.8 as a runtime
    - take a look around and explore some of the options and settings available in lambda
    - edit some of the code in your lambda function and then "deploy" it
    - click test, create a dummy test event and then test the lambda function

- id: 991c9242-a63b-4636-99fb-597fc68e3cf4
  name: Run a data collection job periodically and save the data to S3
  description: |
    - in the lambda editor, write the basics of what you think the function will include in the lambda function
      - try to adhere to lambda function best practices
        - where is your S3 client created?
        - is your bucket name hard-coded or set as an environment variable?
        - see more here
          - https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html
    - create a simple test in the console and run it to check the errors
    - the first major issue you should face is that you dont have the requests module
      - for this, we'll need to create a lambda layer which will contain our dependency
        - to do this, we'll need to install the python library in a folder called python, and then zip up the folder that contains that python folder
          - i.e. if you were to unzip your zipped up package, it would contain a folder called "python", which contains all of the dependency source code
          - this part can be particularly difficult to get right
    - upload this layer to AWS Lambda layers
      - dont forget to add it to your lambda function after you've created it!
    - next, you'll probably face the fact that your lambda function is missing the persmissions you need to create a file on S3
      - you'll need to create an IAM role with s3 full access permissions
        - there is no "write" only permissions like there is "read", so you should use the full access policy
        - bonus: can you restrict this policy to access only the bucket you specified, rather than all?
      - dont forget to assign it to your lambda function as the execution role!
    - you might get the error that the bucket doesnt exist. Have you created it yet?!
    - you should make sure the bucket is in the same region as your lambda function, or otherwise specify the region_name when you create the client
    - your function should be just about working now
    - head over to the cloudwatch console and find the cloudwatch rules section
    - create a new rule which triggers your lambda function every minute
    - check your S3 bucket and the last update time of the objects in there
    - success!
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dockerfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerfile Basics\n",
    "\n",
    "*Dockerfiles* are text-based configuration files used to specify how a Docker image should be built. They play a crucial role in creating consistent and reproducible container environment. A Dockerfile contains a series of instructions that define the image's base, environment setup, and application code and dependencies.\n",
    "\n",
    "### Dockerfile Structure\n",
    "\n",
    "A typical Dockerfile follows a structured format:\n",
    "\n",
    "- *Base Image*: This is the starting point for your Docker image, often based on an existing image from a registry like Docker Hub\n",
    "\n",
    "- *Instructions*: Dockerfiles consist of a series of instructions that specify how the image should be configured and what should be included in it. These instructions include actions like installing software, copying files, and configuring environment variables.\n",
    "\n",
    "- *Commands*: Shell commands are used to execute actions during the image build process. These commands can be used for tasks like installing packages, setting up configurations, or running scripts.\n",
    "\n",
    "Here's a basic Dockerfile structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` docker\n",
    "# This is a comment\n",
    "# Use a base image\n",
    "FROM base_image:tag\n",
    "\n",
    "# Set environment variables\n",
    "ENV key=value\n",
    "\n",
    "# Run commands to install dependencies or configure the image\n",
    "RUN command1 && command2\n",
    "\n",
    "# Copy files from the host to the image\n",
    "COPY source destination\n",
    "\n",
    "# Specify the default command when a container starts\n",
    "CMD [\"executable\", \"param1\", \"param2\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down each component:\n",
    "\n",
    "- **Comments**: Lines starting with # are comments and are ignored during image build\n",
    "\n",
    "- `FROM`: Specifies the base image to use as a starting point. It defines the foundation of your image, often based on official images from Docker Hub. For example, `FROM ubuntu:20.04` sets the base image as Ubuntu 2024.\n",
    "\n",
    "- `ENV`: Sets environment variables within the image, allowing you to configure the runtime environment for your application\n",
    "\n",
    "- `RUN`: Executes commands in the image during the build process. You can use this instruction to install software, update packages, and perform any necessary configuration. For instance, you can use `RUN apt-get update && apt-get install -y package-name` to install packages.\n",
    "\n",
    "- `COPY`: Copies files or directories from the host machine into the image. This is useful for adding application code, configuration files, or assets. For example, `COPY app.py /app/` copies the `app.py` file from your local machine into the `/app` directory in the Docker image.\n",
    "\n",
    "- `CMD`: Specifies the default command that will run when a container is started from the image. It can be overridden when starting a container. For example, `CMD [\"python\", \"app.py\"]` starts the `app.py` script when the container starts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dockerfiles do not contain any extension. The name of the file is literally `Dockerfile`. But an extension might be used, for example, if the Dockerfile specifies the steps for creating an image for an API image, it can be called `api.Dockerfile`.\n",
    "\n",
    "When a Dockerfile is created in VSCode, it will automatically be recognised as a Dockerfile, as indicated by the characteristic whale icon.\n",
    "\n",
    "<p align=center> <img src=images/Docker_icon.png width=200> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dockerfile Commands\n",
    "\n",
    "Each Dockerfile command introduces a new layer in the image creation process, contributing to the overall structure and functionality of the resulting image:\n",
    "\n",
    "- Images can be constructed by building on top of existing layers\n",
    "- Layers are cached and can be reused in consecutive builds, improving build efficiency\n",
    "- Layers can also be shared among different images, enhancing resource utilization\n",
    "\n",
    "#### [FROM](https://docs.docker.com/engine/reference/builder/#from)\n",
    "\n",
    "The `FROM` instruction is the starting point for defining the image-building process. It has the following syntax:\n",
    "\n",
    "> `FROM [--platform=<platform>] <image>[:<tag>] [AS <name>]`\n",
    "\n",
    "Key points to note about the `FROM` instruction:\n",
    "\n",
    "- It initiates the build stage for creating an image\n",
    "- Specifies the base image (e.g., Ubuntu, node, conda) that determines the environment and capabilities of the image\n",
    "- Optionally, you can use `AS` to assign a name to the image, a feature we'll explore in the next lesson when we delve into multi-stage builds\n",
    "\n",
    "The `FROM` instruction can also be combined with `ARG`, allowing you to pass values from the command line during the build process, providing flexibility in image customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version is out of build stage\n",
    "ARG VERSION=latest\n",
    "# Here build stage starts\n",
    "FROM busybox:$VERSION\n",
    "\n",
    "# Gets version into build stage\n",
    "ARG VERSION\n",
    "RUN echo $VERSION > image_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [RUN](https://docs.docker.com/engine/reference/builder/#run)\n",
    "\n",
    "The `RUN` command executes a specified command during the build stage, which is commonly used for tasks such as installing packages. The `RUN` instruction offers two forms:\n",
    "\n",
    "1. `RUN <command>` (executed via `shell`): This form is employed when you intend to execute a command as if it were run within a shell environment, typically `/bin/sh` or `/bin/bash`\n",
    "\n",
    "2. `RUN [\"executable\", \"param1\", \"param2\"]` (exec form): The exec form is utilized when either the base image lacks a shell or you wish to avoid any form of unintended interpretation of the command string\n",
    "\n",
    "To determine which form to use:\n",
    "- Opt for the shell form when you need to execute a command that typically runs within a shell, such as `apt-get install`\n",
    "\n",
    "- Choose the exec form when working with base images that lack a shell or when you desire precise control over the command execution without any string manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint)\n",
    "\n",
    "`ENTRYPOINT` defines the entry point, which is the command executed when a container is created from an image. The `ENTRYPOINT` instruction can be expressed in two forms:\n",
    "\n",
    "1. `ENTRYPOINT [\"executable\", \"param1\", \"param2\"]` (preferred exec form): This form specifies the executable and its parameters to be run when the container starts. This form does not invoke a shell, making it independent of the shell environment. It also permits the use of an optional `CMD` (specified after the command) to provide default arguments or parameters for the entry point command.\n",
    "\n",
    "2. `ENTRYPOINT command param1 param2` (shell form): In the shell form, the entry point command is written as if it were in a shell environment\n",
    "\n",
    "Noteworthy aspects of `ENTRYPOINT`:\n",
    "- The container runs as an executable, a practice that is generally recommended for robust containerization\n",
    "\n",
    "- It is advisable to specify an `ENTRYPOINT` (unless you intend to use shell)\n",
    "\n",
    "- Either `ENTRYPOINT` or `CMD` must be defined for container execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM ubuntu\n",
    "# When we run a container from the image, top -b will be run\n",
    "ENTRYPOINT [\"top\", \"-b\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [CMD](https://docs.docker.com/engine/reference/builder/#cmd)\n",
    "\n",
    "`CMD` defines default arguments for the entry point, which users can potentially override when using docker run. The `CMD` instruction provides several forms:\n",
    "\n",
    "1. `CMD [\"executable\",\"param1\",\"param2\"]`: In this form, you specify the executable as the entry point and provide default parameters. Users have the flexibility to override the entire command if needed.\n",
    "\n",
    "2. `CMD [\"param1\",\"param2\"]`: Here, the parameters `param1` and `param2` are set as default arguments to the previously defined `ENTRYPOINT`. Users can override these parameters during `docker run`.\n",
    "\n",
    "3. `CMD command param1 param2` (shell form, discouraged): The `CMD` instruction is written in a shell form where the `command`, `param1`, and `param2` are included. However, this form is discouraged because it limits users' ability to override the command effectively during `docker run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM ubuntu\n",
    "ENTRYPOINT [\"top\", \"-b\"]\n",
    "CMD [\"-c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we `run` the container from the above image, command `top -b -c` will be run.\n",
    "\n",
    "- `top -b` __will always run__\n",
    "- `-c` can be changed to some other flag/command via `docker run`\n",
    "\n",
    "Let's see how `CMD` interacts with `ENTRYPOINT` for a better understanding. Note: `/bin/sh -c` is just command which executes the proceeding code in the terminal.\n",
    "\n",
    "![](images/docker_entrypoint_cmd_interaction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [COPY](https://docs.docker.com/engine/reference/builder/#copy)\n",
    "\n",
    "`COPY` enables users to specify which file(s) or directories should be copied from the host system into the image using the `COPY` instruction:\n",
    "\n",
    "``` docker\n",
    "COPY <src> <destination>\n",
    "```\n",
    "\n",
    "> One commonly seen idiom is `COPY . .`, which effectively transfers files from the build context (where docker build is executed) to the current working directory inside the container. While it may appear as if files are being copied to the same location, the distinction lies in the two file systems involved:\n",
    "\n",
    "- The first argument to `COPY` references the build context file system, determined by the location where docker build is invoked\n",
    "- The second argument to `COPY` points to the file system within the Docker container\n",
    "\n",
    "#### Other Dockerfile Commands\n",
    "\n",
    "There are a few other note worth commands:\n",
    "\n",
    "- `LABEL <key>=<value>`: Facilitates the addition of metadata to the image, such as authorship, maintenance details, or contact information\n",
    "\n",
    "- `WORKDIR dir`: Allows for the specification of a different working directory within the container\n",
    "\n",
    "- `ENV <key>=<value>`: Sets environment variables that remain accessible throughout the specific build stage\n",
    "\n",
    "- `EXPOSE <port>`: Although it's used less frequently, `EXPOSE` makes a specific port (e.g., `EXPOSE 80`) inside the container available for connections. Users typically specify exposed ports when running the `docker` command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dockerfile Best Practices\n",
    "\n",
    "When writing Dockerfiles, it's essential to follow best practices to create efficient and secure images:\n",
    "\n",
    "- **Use Official Base Images**: Whenever possible, start with official base images provided by the software's maintainers (e.g., Node.js, Python, Nginx) to ensure security and reliability\n",
    "\n",
    "- **Minimize Layer Count**: Limit the number of layers (a layer represent a set of changes) in your image to reduce image size and improve build and push/pull times\n",
    "\n",
    "- **Clean Up**: Remove unnecessary files and dependencies in the same Dockerfile instruction to minimize the image size\n",
    "\n",
    "- **Security**: Ensure your Dockerfile and image follow security best practices, such as not running as root and using trusted sources for software installation\n",
    "\n",
    "- **Documentation**: Include comments and labels in your Dockerfile to document the image's purpose, maintainer, and version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand Cache Management\n",
    "\n",
    "In Docker, some commands can invalidate the cache, necessitating the re-execution of every subsequent step when creating an image.\n",
    "\n",
    "Consider the following Dockerfile example:\n",
    "\n",
    "``` docker\n",
    "\n",
    "FROM ubuntu:18.04\n",
    "\n",
    "RUN apt-get update\n",
    "COPY . .\n",
    "\n",
    "RUN apt-get install -y --no-install-recommends python3\n",
    "RUN rm -rf /var/lib/apt/lists/*\n",
    "```\n",
    "\n",
    "In this case, `python3` will be installed during each docker build regardless of changes in the build context because Docker lacks the capability to determine whether the context for the `COPY` command has changed.\n",
    "\n",
    "Instead, a more efficient approach is to follow the principle of placing `COPY` statements after setting up the operating system dependencies, especially when the installation of packages like Python is not dependent on the build context. This practice helps optimize the use of cache during image builds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining Commands\n",
    "\n",
    "To enhance the efficiency of your Dockerfile, it's advisable to chain multiple commands together using `&&` within a single `RUN` directive whenever possible.\n",
    "\n",
    "Docker operates similarly to git, where it records only the changes (additions) made to the system. However, this behavior can have some undesired consequences:\n",
    "\n",
    "- Temporary files left behind contribute to the image's size \n",
    "- Containers become less opaque, potentially exposing Docker's inner workings and vulnerabilities to attackers\n",
    "\n",
    "It's important to note that the primary command to watch out for is `RUN`, as most commands do not create additional layers. By consolidating multiple commands into a single `RUN` directive, you can optimize image size, maintain container opacity, and enhance the efficiency of your Dockerfile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On: Creating a Dockerfile\n",
    "\n",
    "In this example, you will create a Docker image that runs the `celebrity_births` web scraper. You can download the necessary files for running this scraper [here](https://aicore-files.s3.amazonaws.com/Foundations/DevOps/celebrity_example.zip).\n",
    "\n",
    "After downloading the file, `cd` to that folder, and create a Dockerfile named `Dockerfile`. Inside the Dockerfile, write the following: \n",
    "\n",
    "```docker\n",
    "FROM python:3.8-slim-buster\n",
    "```\n",
    "\n",
    "> Every Docker images start with a base image. This is the foundation upon which your image will be built.\n",
    "\n",
    "Conventionally, Docker images are built from a pre-built image Docker that can be found on Docker Hub. The pre-built image usually contains some dependencies. A common use case is to use an image with Python installed. You can download and run the pre-built image using the `FROM` clause, as indicated above. \n",
    "\n",
    "Thus, with the first added command, we begin creating the image with the necessary Python dependencies.\n",
    "\n",
    "Dockerfiles then consist of a series of instructions that specify how the image should be configure and what should be included in it. These instructions include actions like installing software, copying files, setting environment variables and more. \n",
    "\n",
    "In our example, we will continue by adding the following line to our Dockerfile:\n",
    "\n",
    "``` docker\n",
    "COPY . . \n",
    "```\n",
    "This will copy everything in the Dockerfile directory (`requirements.txt` and the `scraper` folder) into the container.\n",
    "\n",
    "> Understanding this step is extremely important. When an image is built, the relevant files are copied into the container, which is analogous to copying them into a different and separate computer. In other words, it is almost as if there is a separate mini computer containing the scraper, with Python installed.\n",
    "\n",
    "The first `.` argument following the `COPY` instruction is the location of the assets **on your machine** that you wish to copy. The second `.` argument following the `COPY` instruction is the location where the assets will be copied to **on the Docker container**. \n",
    "\n",
    "As the final step before running the scraper, your Python packages must be installed, e.g. `beautifulsoup` and `requests`. Fortunately, the requirements file was also copied into the image. Thus, the packages can be installed directly using the `RUN` command, followed by the bash command:\n",
    "\n",
    "``` docker\n",
    "RUN pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Now, we can run the Python script. Note that the `RUN` clause is unsuitable here because `RUN` is executed when the image is built. This is where you perform actions like installing software, setting up configurations, and adding files to the image. It affects the image's content but doesn't dictate what happens when a container is started from the image. \n",
    "\n",
    "On the other hand, the `CMD` instruction is sued to specify the default command that should be executed when a container is run from the image. In essence, it determines the container's behaviour when it starts:\n",
    "\n",
    "``` docker\n",
    "CMD [\"python\", \"scraper/celebrity_scraper.py\"]\n",
    "```\n",
    "The `CMD` clause can be declared in many ways. In this case, we employ square brackets, and the first item is the executable (`python`), while the rest are the parameters (files). We will discuss in more detail different Dockerfile instructions in a later lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On: Building Docker Images from Dockerfiles\n",
    "\n",
    "To create a Docker image, you use the `docker build` command. This command reads the instructions in a Dockerfile and executes them step by step to construct the image. Each instruction in the Dockerfile results in a new image layer. Therefore, Docker images are constructed from multiple layers, and each layer represents a set of changes or instructions from the Dockerfile.\n",
    "\n",
    "The basic syntax for building an image is as follows: `docker build -t <image_name>:<tag> <path_to_Dockerfile_directory>`.\n",
    "\n",
    "- `-t`: Specifies the name and optional tag for the image. Tags provide a way to version your images (e.g., my-app:1.0).\n",
    "\n",
    "- `<image_name>`: The name you want to give to your Docker image\n",
    "\n",
    "- `<tag>`: An optional tag for versioning your image\n",
    "\n",
    "- `<path_to_Dockerfile_directory>`: The directory where your Dockerfile is located\n",
    "\n",
    "You can view all the options [here](https://docs.docker.com/engine/reference/commandline/build/).\n",
    "\n",
    "For example, to build an image named `my-app` with the tag `v1.0` from a Dockerfile in the current directory, you would run: `docker build -t my-app:v1.0`.\n",
    "\n",
    "> The typical naming convention for Docker images is `image_name:version`. Typically we specify the version as `latest` rather than manually writing out the semantic versioning label.\n",
    "\n",
    "Going back to our previous scraper hands-on, to build the Docker image from the previously created Dockerfile, in the CLI, change the directory to `celebrity_example`. Then use the `build` command from Docker following the syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker build -t celebrities:latest ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are in the same directory as the Dockerfile, the Dockerfile path is simply a dot (`.`). To verify if the image was successfully created, you can run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker images # show our current images on this machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=center> <img src=images/Docker_images.png width=600> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Image Building Techniques\n",
    "\n",
    "### Docker Build Context\n",
    "\n",
    "The *Docker build context* is the foundation upon which Docker images are constructed. It comprises a set of files and directories that Docker has access to during the image creation process. Understanding how the build context works is vital because it influences what gets included in the image and directly impacts image size and build speed.\n",
    "\n",
    "> The build context is determined by the directory you specify when you run the `docker build` command. Everything within this directory and its subdirectories is part of the build context.\n",
    "\n",
    "Consider a scenario where you have a directory with your application code, configuration files, and some large dataset. If you specify this directory as the build context, Docker will include all these files in the image, making it much larger than necessary.\n",
    "\n",
    "### `.dockerignore` File\n",
    "\n",
    "> The `.dockerignore` file is a key component of managing the Docker build context effectively. It is a plain text file in which you can define rules for excluding files and directories from the Docker build context, ensuring that only essential data is sent to the Docker daemon during image builds. This not only improves build performance but also reduces the risk of including unnecessary or sensitive information in the image.\n",
    "\n",
    "The format of a `.dockerignore` file is straightforward. Each line typically represents a pattern or a rule, and Docker uses these rules to determine what should not be included when building the image. Here is an example of a basic `.dockerignore` file:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Exclude temporary files\n",
    "*.temp\n",
    "*.log\n",
    "\n",
    "# Exclude development files\n",
    "dev/\n",
    "\n",
    "# Exclude sensitive configuration\n",
    "secrets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the `*.temp` and `*.log` patterns ensure that any temporary or log files are excluded. The `dev/` pattern excludes the entire `dev` directory, and the `secrets/` pattern ensures that any sensitive configuration files within the `secrets` directory are not included.\n",
    "\n",
    "Understanding the scenarios in which you should use `.dockerignore` files is essential for efficient Docker image management. Here are some common use cases:\n",
    "\n",
    "- **Excluding Development Artifacts**: When working on a development project, exclude files like build artifacts, IDE-specific files, and debug logs from the build context to keep the image clean and focused\n",
    "\n",
    "- **Enhancing Security**: Exclude sensitive files such as credentials, private keys, and configuration files from the build context to prevent them from being inadvertently included in the Docker image\n",
    "\n",
    "- **Minimizing Image Size**: Exclude files that are not required at runtime, like documentation, tests, or non-essential assets, to create leaner and more efficient Docker images\n",
    "\n",
    "- **Improving CI/CD Pipeline Speed**: In CI/CD pipelines, minimizing the build context size can significantly reduce build times, ensuring faster deployments and integration testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Stage Builds\n",
    "\n",
    "*Multi-stage builds* are a feature in Docker that enable you to create multiple stages (or intermediate images) within a single Dockerfile. Each stage represents a phase in the image-building process, and the final image is built by copying artifacts from one or more of these stages. This approach helps you achieve two important goals:\n",
    "\n",
    "- **Efficiency**: Multi-stage builds allow you to optimize the size of the final image by including only what's necessary. Unnecessary build tools and dependencies can be discarded, resulting in leaner and more efficient images.\n",
    "\n",
    "- **Modularity**: Dockerfiles can become complex as projects grow. Multi-stage builds improve modularity by breaking down the image creation process into distinct stages, making it easier to manage and maintain Dockerfiles.\n",
    "\n",
    "Suppose you are developing a Python web application that relies on external dependencies managed by `pip`. To create an optimized production image, you can leverage multi-stage builds. Here's a breakdown of the Dockerfile:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` dockerfile\n",
    "# Stage 1: Build Dependencies\n",
    "FROM python:3.9 as builder\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Install application dependencies\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Stage 2: Create Production Image\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy only the application code and installed dependencies\n",
    "COPY --from=builder /usr/local/lib/python3.9/site-packages /usr/local/lib/python3.9/site-packages\n",
    "COPY . .\n",
    "\n",
    "# Set environment variables, configure application settings, etc.\n",
    "\n",
    "# Your application startup command\n",
    "CMD [\"python\", \"app.py\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "- **Stage 1 (builder)**: This stage is responsible for installing application dependencies specified in `requirements.txt`. By separating this step, you ensure that only necessary dependencies are included in the final image.\n",
    "\n",
    "- **Stage 2**: In this stage, you create the production image based on a lightweight Python image (`python:3.9-slim`). You copy the installed dependencies from the builder stage and then copy your application code into the image. This results in a production-ready image that contains only what is needed to run your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On: Running Docker Containers\n",
    "\n",
    "Running a Docker container is straightforward using the `docker run` command. Here's the basic syntax:\n",
    "\n",
    "`docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]`\n",
    "\n",
    "To run the `celebrities image`, you would use the following command: `docker run celebrities`\n",
    "\n",
    "This will throw an error because the script expects an input. However, at present, this is impossible because the image is running in a non-interactive mode. As a solution, we must add the options, `-i` and `-t`: `-i` will keep the STDIN open, and `-t` will make the process interactive.\n",
    "\n",
    "<p align=center> <img src=images/Docker_run_error.png width=600> </p>\n",
    "\n",
    "`docker run -it celebrities`\n",
    "\n",
    "<p align=center> <img src=images/Docker_run.png width=600> </p>\n",
    "\n",
    "There other common Docker container operations you may need to use. These include:\n",
    "\n",
    "- **Stopping a Container**: To stop a running container gracefully, you can use the `docker stop` command followed by the container's ID or name `docker stop <container_id_or_name>`. You can obtain the image ID using the `docker images` command.\n",
    "\n",
    "- **Removing a Container**: If you want to remove a stopped container, you can use the `docker rm` command with the container's ID or name: `docker rm <container_id_or_name>`\n",
    "\n",
    "- **Listing Running Containers**: To see a list of running containers, you can run the `docker ps` command\n",
    "\n",
    "- **Listing All Containers**: To see a list of all containers (including stopped ones), you can use the `-a` flag with docker `ps`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On: Pushing Images to Docker Hub\n",
    "\n",
    "Now that we have successfully build the `celebrities` image in the previous hands-on, the image can be used everywhere, regardless of the OS and dependencies installed. Additionally, you can distribute it globally using Docker Hub. To do this, you need to log in to your Docker Hub account using the CLI:\n",
    "\n",
    "```\n",
    "docker login\n",
    "```\n",
    "\n",
    "You will be prompted to enter your Docker Hub username and password. After entering your credentials, you should see a successful login message.\n",
    "\n",
    "> Before pushing an image to Docker Hub, you need to tag it with the appropriate repository name and optionally specify a tag. The repository name typically follows the format `<username>/<image_name>`.\n",
    "\n",
    "Use the `docker tag` command to add the repository name and tag to your image: `docker tag <image_id> <username>/<image_name>:<tag>`.\n",
    "\n",
    "- `<image_id>`: The image ID of your existing Docker image. You can find this out by running `docker images`.\n",
    "- `<username>/<image_name>`: The repository name on Docker Hub where you want to push the image\n",
    "- `<tag>` (optional): A specific tag for versioning your image (e.g., v1.0). If not specified, it defaults to latest\n",
    "\n",
    "Let's tag our previously created image:\n",
    "\n",
    "```\n",
    "docker tag 82a51cbd4876 ivanyingx/celebrities:v1\n",
    "```\n",
    "Above, `ivanyingx` is the username, which you should replace with yours, and `82a51cbd4876` is the image ID. Afterwards, confirm that the image has been properly built by running `docker images` once more.\n",
    "\n",
    "<p align=center> <img src=images/Docker_tag.png width=800 height=100> </p>\n",
    "\n",
    "Incidentally, it is also possible to confirm this information in Docker Desktop if you are on Mac or Windows:\n",
    "\n",
    "<p align=center> <img src=images/Docker_Desktop.png width=900 height=600> </p>\n",
    "\n",
    "With the image tagged, you can now push it to Docker Hub using the `docker push` command: `docker push <username>/<image_name>:<tag>`. Which for this example will be: `docker push ivanyingx/celebrities:v1`.\n",
    "\n",
    "To verify that your image has been uploaded, go to your Docker Hub account and check you can see the newly pushed image\n",
    "\n",
    "<p align=center> <img src=images/Docker_Hub_example.png width=1000 height=400> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any other Docker Hub user wants to run your container, they can do so directly on their local machine. For example, in this case, you can run `ivanyingx`'s image as follows:\n",
    "\n",
    "run `docker pull ivanyingx/celebrities` to download the image\n",
    "\n",
    "and `docker run ivanyingx/celebrities` to run the image.\n",
    "\n",
    "It is also possible to run `docker run ivanyingx/celebrities` directly, which will perform both operations.\n",
    "\n",
    "Congratulations! You've successfully built and pushed your first Docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Dockerfiles are text-based configuration files that define how Docker images should be built\n",
    "- Dockerfile structure includes base image selection, instructions for setting up the environment, copying files, running commands, exposing ports, and defining the default command\n",
    "- Best practices when creating Dockerfiles include: minimizing image layers, version tagging of base images, and adhering to security measures\n",
    "- `FROM` sets the base image, defining the initial environment for your Docker image\n",
    "- `RUN` executes commands during image creation, used for installing software and configuration tasks\n",
    "- `COPY` copies files or directories into the image, crucial for adding application code and assets\n",
    "- `ENTRYPOINT` defines the primary command when a container starts, while `CMD` provides default arguments that can be overridden during docker run\n",
    "- Commands that invalidate the cache can lead to re-execution of subsequent steps; optimizing cache usage involves careful consideration of `COPY` placement and chaining commands using `&&` in a single `RUN` directive"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
